<img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png" alt="AWS" width="250"/>

# AWS Systems Manager - Security Playbook <!-- omit in toc -->
## NIST Cybersecurity Framework Alignment <!-- omit in toc -->

**Generated By:**  
Josh Lutrell

## Table of Contents <!-- omit in toc -->
- [Disclaimer](#disclaimer)
- [Overview](#overview)
- [Preventative Controls](#preventative-controls)
  - [1. Permissions within the service are established in line with individual need and least-privilege is enforced](#1-Permissions-within-the-service-are-established-in-line-with-individual-need-and-least-privilege-is-enforced)
  - [2. Data is protected](#2-Data-is-protected)
  - [3. Infrastructure must be secured for monitoring, audit, availability, and access control](#3-Infrastructure-must-be-secured-for-monitoring,-audit,-availability,-and-access-control)
- [Detective](#detective)
  - [1. Establish network/application monitoring controls](#1-establish-networkapplication-monitoring-controls)
  - [2. AWS Systems Manager Patch Manager](#2-run-vulnerability-scans-on-images-stored-in-ecr)
- [Respond/Recover](#respondrecover)
  - [1. Utilize Amazon EventBridge for automated incident response](#1-utilize-amazon-eventbridge-for-automated-incident-response)
- [Endnotes](#endnotes)

## Overview
AWS provides a number of security features for AWS Systems Manager which help you comply with the NIST Cybersecurity Framework. The following playbook will outline what the AWS best practices are, how they align to NIST, and how to implement these best practices within your organization.

These NIST Controls and Subcategories are not applicable to this service: ID, PR.AC-2, PR.AT, PR.DS-3, PR.DS-7, PR.DS-8, PR.IP (Unless Stated), PR.MA, PR.PT-2, PR.PT-3, DE.AE-4, DE.AE-5, DE.CM-2, DE.CM-6, DE.DP, RS.RP, RS.CO, RS.MI, RS.IM, RC

## Preventative Controls
### 1. Permissions within the service are established in line with individual need and least-privilege is enforced
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.AC-1|Identities and credentials are issued, managed, verified, revoked, and audited for authorized devices, users and processes|
|PR.AC-4|Access permissions and authorizations are managed, incorporating the principles of least privilege and separation of duties|
|PR.AC-6|Identities are proofed and bound to credentials and asserted in interactions|
|PR.AC-7|Users, devices, and other assets are authenticated (e.g., single-factor, multi-factor) commensurate with the risk of the transaction (e.g., individuals’ security and privacy risks and other organizational risks)|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|5|AWS IAM User accounts are only to be created for use by services or products that do not support IAM Roles. Services are not allowed to create local accounts for human use within the service. All human user authentication will take place within CG’s Identity Provider.|
|8|AWS IAM User secrets, including passwords and secret access keys, are to be rotated every 90 days. Accounts created locally within any service must also have their secrets rotated every 90 days.|
|10|Administrative access to AWS resources will have MFA enabled|

**Why?** Different users/services will require different levels of access within the service. Having clearly defined policies and limiters will ensure that a user is not able to manage build projects in ways that they shouldn't be able to.

**How?** Use fine-grained access permissions for all Systems Manager capabilities by using AWS Identity and Access Management (IAM) policies.
* For more information, see [Customer Managed Policies](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#customer-managed-policies)

**1.1. Implement least privilege access**

When granting permissions, you decide who is getting what permissions to which Systems Manager resources. You enable specific actions that you want to allow on those resources. Therefore you should grant only the permissions that are required to perform a task. Implementing least privilege access is fundamental in reducing security risk and the impact that could result from errors or malicious intent.

The following tools are available to implement least privilege access:
* [IAM user policies](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-with-s3-actions.html) and [Permissions Boundaries for IAM Entities](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html)
* [Service Control Policies](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html)

**1.2. AWS Systems Manager Service-Linked Roles**

AWS Systems Manager uses AWS IAM service-linked roles. A service-linked role is a unique type of IAM role that is linked directly to Systems Manager. Service-linked roles are predefined by Systems Manager and include all the permissions that the service requires to call other AWS services on your behalf. For more information, see [service-linked roles with System Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/using-service-linked-roles.html)

Service-linked roles allows for easier setup of System Manager since you don’t have to manually add the necessary permissions. Systems Manager defines the permissions of its service-linked roles, and unless defined otherwise, only Systems Manager can assume its roles. The defined permissions include the trust policy and the permissions policy, and that permissions policy cannot be attached to any other IAM entity.

**Creating a service-linked role (console)**

1. In the navigation pane of the IAM console, choose Roles. Then choose Create role.
2. Choose the AWS Service role type, and then choose the service that you want to allow to assume this role.
3. Choose the use case for your service. If the specified service has only one use case, it is selected for you. Use cases are defined by the service to include the trust policy required by the service. Then choose Next: Permissions.
4. Choose one or more permissions policies to attach to the role. Depending on the use case that you selected, the service might do any of the following:
    * Define the permissions used by the role
    * Allow you to choose from a limited set of permissions
    * Allow you to choose from any permissions
    * Allow you to select no policies at this time, create the policies later, and then attach them to the role.
    * Select the box next to the policy that assigns the permissions that you want the role to have, and then choose Next: Tags.
    * The permissions that you specify are available to any entity that uses the role. By default, a role has no permissions.
5. Choose Next: Review. You cannot attach tags to service-linked roles during creation. For more information about using tags in IAM, see Tagging IAM users and roles.
6. For Role name, the degree of role name customization is defined by the service. If the service defines the role's name, then this option is not editable. In other cases, the service might define a prefix for the role and allow you to type an optional suffix.
7. If possible, type a role name suffix to add to the default name. This suffix helps you identify the purpose of this role. Role names must be unique within your AWS account. They are not distinguished by case. For example, you cannot create roles named both `<service-linked-role-name>_SAMPLE` and `<service-linked-role-name>_sample`. Because various entities might reference the role, you cannot edit the name of the role after it has been created.
8. (Optional) For Role description, edit the description for the new service-linked role.
9. Review the role and then choose Create role.

**Creating a service-linked role (AWS CLI)**

```bash
aws iam create-service-linked-role --aws-service-name SERVICE-NAME.amazonaws.com
```

**Creating a service-linked role (AWS API)**

Use the `CreateServiceLinkedRole` API call. In the request, specify a service name of `SERVICE_NAME_URL.amazonaws.com`.
* For example, to create the System Manager service-linked role, use `ssm.amazonaws.com`.

### 2. Data is protected
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.DS-1|Data-at-rest is protected|
|PR.DS-2|Data-in-transit is protected|
|PR.DS-5|Protections against data leaks are implemented|
|PR.DS-6|Integrity checking mechanisms are used to verify software, firmware, and information integrity|
|PR.IP-1|A baseline configuration of information technology/industrial control systems is created and maintained incorporating security principles (e.g. concept of least functionality)|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|1|All Data-at-rest must be encrypted and use a Capital Group BYOK encryption key|
|2|All Data-in-transit must be encrypted using certificates using Capital Group Certificate Authority|
|3|Keys storied in a Key Management System (KMS) should be created by Capital Group's hardware security module (HSM) and are a minimum of AES-256|

**Why?** Data should be protected in-transit between the customer and AWS, as well as within AWS Services using NIST-approved encryption mechanism.

### Encryption at Rest

**How?** Parameter Store is a feature of Amazon EC2 Systems Manager. It provides a centralized, encrypted store for sensitive information and has many advantages when combined with other capabilities of Systems Manager, such as Run Command and State Manager. The service is fully managed, highly available, and highly secured. 

The types of parameters you can create in Parameter Store include `String`, `StringList`, and `SecureString`. Do not store sensitive data in a `String` or `StringList` parameter. Use only `SecureString` parameter type for sensitive data that must remain encrypted. To encrypt `SecureString` parameter values, Parameter Store uses an AWS Key Management Service (AWS KMS) customer master key (CMK). Use customer managed CMK to encrypt the parameter value in an AWS managed database.

**Parameter Store Parameter types**

Parameter Store provides support for three types of parameters: `String`, `StringList`, and `SecureString`. For more information on all Parameter Types, see [Parameter types and examples](https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-about-examples.html). 

**1. String**

By default, String parameters consist of any block of text you enter. For example: `abc123`

Parameter Store will not perform validation on inputted value, if parameter value is entered as plain text. For `String` parameters, however, you can specify the data type as `aws:ec2:image`, and Parameter Store validates that the value you enter is the proper format for an Amazon EC2 AMI; for example: `ami-12345abcdeEXAMPLE`.
* Use the `DataType` option to validate supplied parameter value is a properly formatted Amazon EC2 AMI ID, as shown in the following example AWS CLI command. You do not need to specify a data type in any other cases. 

```bash
aws ssm put-parameter \
    --name "golden-ami" \
    --type "String" \
    --data-type "aws:ec2:image" \
    --value "ami-12345abcdeEXAMPLE"
```
**2. StringList**

`StringList` parameters contain a comma-separated list of values. For example: `CSV,TSV,CLF,ELF,JSON` or `Monday,Wednesday,Friday`

```bash
aws ssm put-parameter \
    --name "MyStringListParameter" \
    --type "StringList" \
    --value "North,South,East,West"
```

**4. SecureString**

The `SecureString` parameter type can be used for textual data that you want to encrypt, such as passwords, application secrets, confidential configuration data, or any other types of data you need to protect. Please note, only the value of a `SecureString` parameter is encrypted. Parameter names, descriptions, and other properties are not encrypted.

When to use `SecureString` parameters
* Using data/parameters across AWS services without exposing the values as plain text in commands, functions, agent logs, or AWS CloudTrail logs.
* Control user access to sensitive data
* Ability to audit when sensitive data is accessed (AWS CloudTrail)
* To encrypt sensitive data and want to bring your own encryption keys to manage access

Example for when to use `SecureString`: When you run a command in Run Command, do not include any sensitive information formatted as plaintext, such as passwords, configuration data, or other secrets. All Systems Manager API activity in your account is logged in an Amazon S3 bucket, in AWS CloudTrail logs. This means that any user with access to that S3 bucket can view the plaintext values of those secrets. For this reason, we strongly recommend creating and using `SecureString` parameters to encrypt the sensitive data you use in your Systems Manager operations.

`SecureString` data is encrypted and decrypted using a AWS KMS customer master key (CMK). When using a customer managed key, the IAM policy that grants a user access to a parameter or parameter path must provide explicit `kms:Encrypt` permissions for the key. For example, the following policy allows a user to create, update, and view `SecureString` parameters that begin with "prod-" in the specified Region and account.

The required KMS permissions for this policy are `kms:Decrypt`, `kms:Encrypt` and `kms:GenerateDataKey`. The `kms:GenerateDataKey` permission is required for creating encrypted advanced parameters using the specified customer managed key.

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ssm:PutParameter",
                "ssm:GetParameter",
                "ssm:GetParameters"
            ],
            "Resource": [
                "arn:aws:ssm:us-east-2:111122223333:parameter/prod-*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
               "kms:Decrypt",
               "kms:Encrypt",
               "kms:GenerateDataKey"  
            ],
            "Resource": [
                "arn:aws:kms:us-east-2:111122223333:key/1234abcd-12ab-34cd-56ef-12345EXAMPLE"
            ]
        }
    ]
}
```
To use a customer managed CMK you must specify the key by using the `--key-id parameter`. The parameter supports the following KMS parameter formats.

|KMS Parameter|Example|
|-------------|------------------------|
|Key ARN|`arn:aws:kms:us-east-2:123456789012:key/12345678-1234-1234-1234-123456789012`|
|Alias ARN|`arn:aws:kms:us-east-2:123456789012:alias/MyAliasName`|
|Key ID|`12345678-1234-1234-1234-123456789012`|
|Alias Name|`alias/MyAliasName`|

AWS CLI example for creating a `SecureString` parameter.  
```bash
aws ssm put-parameter \
    --name parameter-name \
    --value "parameter-value" \
    --type SecureString \
    --key-id arn:aws:kms:us-east-2:123456789012:key/1a2b3c4d-1a2b-1a2b-1a2b-1a2b3c4d5e
```
For more information on `SecureString` parameters, see [SecureString parameters](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-securestring.html).

**Storing Contents in Amazon S3 Buckets**

As part of your Systems Manager operations, you might choose to upload or store data in one or more Amazon Simple Storage Service (Amazon S3) buckets.

For information about S3 bucket encryption, see [Protecting Data Using Encryption](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html) and [Data Protection in Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/DataDurability.html) in the Amazon Simple Storage Service Developer Guide.

The following are types of data you can upload or have stored in S3 buckets as part of your Systems Manager activities.
* The output of Run Command commands
* Distributor packages
* Patch Manager patching operation logs
* Patch Manager patch override lists
* Scripts or Ansible Playbooks to run in an Automation document workflow
* Chef InSpec profiles for use with Compliance scans
* AWS CloudTrail logs
* Session Manager session history logs
* Reports from Explorer or OpsData from OpsCenter
* AWS CloudFormation templates for use with Automation workflows
* Compliance data from a Resource Data Sync scan
* Output of requests to create or edit State Manager association on managed instances
* Custom SSM documents that you can run using the AWS managed AWS-RunDocument document

### Encryption in Transit

**How?** All communication between clients and instances must be encrypt with a custom TLS 1.2 certificate.

By default Systems Manager provides the following support for encryption of your data in transit

**1. Connections to Systems Manager API endpoints**
* Systems Manager API endpoints only support secure connections over HTTPS. When you manage Systems Manager resources with the AWS Management Console, AWS SDK, or the Systems Manager API, all communication is encrypted with Transport Layer Security (TLS). For a full list of API endpoints, see [Regions and Endpoints](https://docs.aws.amazon.com/general/latest/gr/rande.html) in the Amazon Web Services General Reference

**2. Managed instances**
* AWS provides secure and private connectivity between EC2 instances. In addition, we automatically encrypt in-transit traffic between supported instances in the same VPC or in peered VPCs, using AEAD algorithms with 256-bit encryption. This encryption feature uses the offload capabilities of the underlying hardware, and there is no impact on network performance.

    |Supported Instances|
    |----------|
    |C5n|
    |G4|
    |I3en|
    |M5dn|
    |M5n|
    |P3dn|
    |R5dn|
    |R5n|

**3. Session Manager sessions**
* By default, Session Manager uses TLS 1.2 to encrypt session data transmitted between the local machines of users in your account and your EC2 instances. To further encrypt the data in transit use a customer master key (CMK) that has been created in AWS Key Management Service.

**4. Run Command access**
* By default, remote access to your instances using Run Command is encrypted using TLS 1.2, and requests to create a connection are signed using SigV4.

### 3. Infrastructure must be secured for monitoring, audit, availability, and access control
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.PT-1|Audit/log records are determined, documented, implemented, and reviewed in accordance with policy|
|PR.PT-4|Communications and control networks are protected|
|PR.PT-5|Mechanisms (e.g., failsafe, load balancing, hot swap) are implemented to achieve resilience requirements in normal and adverse situations|
|PR.AC-3|Remote access is managed|
|PR.AC-5|Network integrity is protected (e.g., network segregation, network segmentation)|
|PR.DS-4|Adequate capacity to ensure availability is maintained|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|6|Any AWS service used by CG should not be directly available to the Internet and the default route is always the CG gateway.|

**3.1 Create VPC Endpoints for Systems Manager**

**Why?** You can improve the security posture of your managed instances by configuring AWS Systems Manager to use an interface VPC endpoint in Amazon VPC. An interface VPC endpoint enables you to connect to services powered by AWS PrivateLink, a technology that enables you to privately access Amazon EC2 and Systems Manager APIs by using private IP addresses. PrivateLink restricts all network traffic between your managed instances, Systems Manager, and Amazon EC2 to the Amazon network.

**How?** To use Systems Manager through VPC. First create the required interface endpoints for Systems Manager and create the required gateway endpoint for Systems Manager to access Amazon S3. 

First, create three required and one optional interface endpoints for Systems Manager. The first three endpoints are required for Systems Manager to work in a VPC. The fourth, `com.amazonaws.region.ssmmessages`, is required only if you are using Session Manager capabilities.

**1. Creating an Interface Endpoint to create the following interface endpoints**

For assistance with creating a VPC Interface Endpoint. Please reference the [VPC Runbook](https://github.com/open-itg/aws_runbooks/blob/master/vpc/RUNBOOK.md) or [AWS Documentation](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.html#create-interface-endpoint).

|Interface Endpoints|Description|
|-------------|------------------------|
|`com.amazonaws.region.ssm`|The endpoint for the Systems Manager service|
|`com.amazonaws.region.ec2messages`|Systems Manager uses this endpoint to make calls from SSM Agent to the Systems Manager service|
|`com.amazonaws.region.ec2`| If you're using Systems Manager to create VSS-enabled snapshots, you need to ensure that you have an endpoint to the EC2 service. Without the EC2 endpoint defined, a call to enumerate attached EBS volumes fails, which causes the Systems Manager command to fail|
|`com.amazonaws.region.ssmmessages` (optional)|This endpoint is required only if you are connecting to your instances through a secure data channel using Session Manager. For more information, see [AWS Systems Manager Session Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html) and [Reference: ec2messages, ssmmessages, and other API calls](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-setting-up-messageAPIs.html)|

**2. Creating a Gateway Endpoint to create the following gateway endpoint for Amazon S3**

For assistance with creating a VPC Gateway Endpoint. Please reference the [VPC Runbook](https://github.com/open-itg/aws_runbooks/blob/master/vpc/RUNBOOK.md) or [AWS Documentation](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html#create-gateway-endpoint).

|Gateway Endpoints|Description|
|-------------|------------------------|
|`com.amazonaws.region.s3`|Systems Manager uses this endpoint to update SSM Agent and for tasks like uploading output logs you choose to store in S3 buckets, retrieving scripts or other files you store in buckets, and so on.|

**3.2 Enable Logging to Cloudtrails & Cloudtrail to Splunk**

**Why?** Systems Manager is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Systems Manager. CloudTrail captures all API calls for Systems Manager as events, including calls from the Systems Manager console and from code calls to the Systems Manager APIs.

**How?** Every event or log entry contains information about who generated the request. The identity information helps you determine the following:
* Whether the request was made with root or AWS Identity and Access Management (IAM) user credentials.
* Whether the request was made with temporary security credentials for a role or federated user.
* Whether the request was made by another AWS service.

A trail is a configuration that enables delivery of events as log files to an S3 bucket that you specify. CloudTrail log files contain one or more log entries. An event represents a single request from any source and includes information about the requested action, the date and time of the action, request parameters, and so on. CloudTrail log files are not an ordered stack trace of the public API calls, so they do not appear in any specific order.

The following example shows a CloudTrail log entry that demonstrates the DeleteDocuments action on a document named example-Document

```json
{
    "eventVersion": "1.04",
    "userIdentity": {
        "type": "AssumedRole",
        "principalId": "AKIAI44QH8DHBEXAMPLE:203.0.113.11",
        "arn": "arn:aws:sts::123456789012:assumed-role/example-role/203.0.113.11",
        "accountId": "123456789012",
        "accessKeyId": "AKIAIOSFODNN7EXAMPLE",
        "sessionContext": {
            "attributes": {
                "mfaAuthenticated": "false",
                "creationDate": "2018-03-06T20:19:16Z"
            },
            "sessionIssuer": {
                "type": "Role",
                "principalId": "AKIAI44QH8DHBEXAMPLE",
                "arn": "arn:aws:iam::123456789012:role/example-role",
                "accountId": "123456789012",
                "userName": "example-role"
            }
        }
    },
    "eventTime": "2018-03-06T20:30:12Z",
    "eventSource": "ssm.amazonaws.com",
    "eventName": "DeleteDocument",
    "awsRegion": "us-east-2",
    "sourceIPAddress": "203.0.113.11",
    "userAgent": "example-user-agent-string",
    "requestParameters": {
        "name": "example-Document"
    },
    "responseElements": null,
    "requestID": "86168559-75e9-11e4-8cf8-75d18EXAMPLE",
    "eventID": "832b82d5-d474-44e8-a51d-093ccEXAMPLE",
    "resources": [
        {
            "ARN": "arn:aws:ssm:us-east-2:123456789012:document/example-Document",
            "accountId": "123456789012"
        }
    ],
    "eventType": "AwsApiCall",
    "recipientAccountId": "123456789012"
}
```

**3.3 Implement monitoring using Amazon CloudWatch monitoring tools**

**Why?** Monitoring is an important part of maintaining the reliability, security, availability, and performance of Systems Manager and your AWS solutions. CloudWatch provides several tools and services to help you monitor Systems Manager and your other AWS services.

**How?** You can configure rules in Amazon CloudWatch Events to alert you to changes in Systems Manager resources, and to direct CloudWatch Events to take actions based on the content of those events. CloudWatch Events provides support for a number of events that are emitted by various Systems Manager capabilities.

Following are lists of the Systems Manager event types with built-in monitoring support in CloudWatch Events.

**3.3.1. Session Manager Session Activity**

Session Manager provides you with options for auditing and logging session activity in your AWS account. 

This allows you to do the following:
* Details of every connection made to your instances using Session Manager
* Automatically initiate another action on an AWS resource as the result of session activity, such as running an AWS Lambda function, starting an AWS CodePipeline pipeline, or running an AWS Systems Manager Run Command document

**Configure CloudWatch Events for Session Manager Activities (console)**

1. In the navigation pane, choose Session Manager.
2. Choose the Preferences tab, and then choose Edit.
3. Select the check box next to CloudWatch logs.
4. For CloudWatch logs, to specify the existing CloudWatch Logs log group in your AWS account to upload session logs to, select one of the following:
    * Choose a log group from the list: Select a log group that has already been created in your account to store session log data.
    * Enter a log group name in the text box: Enter the name of a log group that has already been created in your account to store session log data.
5. Choose Save.

**Configure CloudWatch Events for Session Manager Activities (command line)**

1. Create a JSON file on your local machine with a name such as `SessionManagerRunShell.json`, and then paste the following content into it
    * Specify where you want to send session data. You can specify an S3 bucket name (with an optional prefix) or a CloudWatch Logs log group name.

    ```json
    {
    "schemaVersion": "1.0",
    "description": "Document to hold regional settings for Session Manager",
    "sessionType": "Standard_Stream",
    "inputs": {
        "s3BucketName": "DOC-EXAMPLE-BUCKET",
        "s3KeyPrefix": "MyBucketPrefix",
        "s3EncryptionEnabled": true,
        "cloudWatchLogGroupName": "MyLogGroupName",
        "cloudWatchEncryptionEnabled": true,
        "kmsKeyId": "MyKMSKeyID",
        "runAsEnabled": true,
        "runAsDefaultUser": "MyDefaultRunAsUser"
    }
    }
    ```
2. Save the file.
3. In the directory where you created the JSON file, run the following command
    ```bash
    aws ssm update-document \
        --name "SSM-SessionManagerRunShell" \
        --content "file://SessionManagerRunShell.json" \
        --document-version "\$LATEST"
    ```


**3.3.2. Run Command**

Supported Events Include:
* Status change for a command (applies to one or more instances)
* Status change for a command invocation (applies to one instance only)

You can also specify Run Command as a target action when a CloudWatch event occurs. For example, if a CloudWatch event is triggered that an instance in an Auto Scaling group is about to terminate. 
* You can configure CloudWatch so the target of that event is a Run Command script that captures the log files from the instance before it is terminated. 
* You can also configure a Run Command action when a new instance is created in an Auto Scaling group. For example, when CloudWatch receives the instance-created event, Run Command could enable the web server role or install software on the instance.

**Configure CloudWatch Events for Run Command**
1. In the left navigation pane, under Events, choose Rules, and then choose Create rule.
2. Under Event Source, verify that Event Pattern is selected.
3. In the Service Name field, choose EC2 Simple Systems Manager (SSM)
4. In the Event Type field, choose Run Command.
5. Choose the detail types and statuses for which you want to receive notifications, and then choose Add targets.
6. In the Select target type list, choose a target type. For information about the different types of targets, see the corresponding AWS Help documentation.
7. Choose Configure details.
8. Specify the rule details, and then choose Create rule.

**Configure Run Command as a CloudWatch Events target**
1. In the left navigation pane, choose Events, and then either choose to create a new rule or edit an existing rule.
2. After specifying or verifying the details of the rule, choose Add target.
3. In the Select target type list, choose SSM Run Command.
4. In the Document list, choose an SSM document. The document determines the type of actions Run Command can perform on your instances.
5. In the Target key field, specify either InstanceIds or tag:EC2_tag_name. Here are some examples of a Target key that uses an EC2 tag: tag:production and tag:server-role.
6. In the Target value(s) field, if you chose InstanceIds in the previous step, specify one or more instance IDs separated by commas. If you chose tag:EC2_tag_name in the previous step, specify one or more tag values. After you type the value, for example web-server or database, choose Add.
7. In the Configure parameter(s) section, choose an option and then complete any fields populated by your choice. Use the hover text for more information about the options. For more information about the parameter fields for your document, see [Running commands using Systems Manager Run Command](https://docs.aws.amazon.com/systems-manager/latest/userguide/run-command.html) and choose the procedure for your document.
8. In the permissions section, choose Create a new role for this specific resource to create a new role with the required instance profile role for Run Command. Or, choose Use existing role. For more information about roles required for Run Command, see [Setting up AWS Systems Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-setting-up.html).
9. Choose Configure details and complete the wizard.

**3.3.3. Automation**

Supported Events Include:
* Status change for an automation execution
* Status change for a single step in an automation execution

Configure Amazon CloudWatch Events to notify you of Systems Manager Automation events. For example, you can configure CloudWatch Events to send notifications when an Automation step succeeds or fails. You can also configure CloudWatch Events to send notifications if the Automation workflow succeeds or fails.

**Configure CloudWatch Events for Automation**
1. Choose Events in the left navigation, and then choose Create rule.
2. Under Event Source, verify that Event Pattern is selected.
3. In the Service Name field, choose EC2 Simple Systems Manager (SSM)
4. In the Event Type field, choose Automation.
5. Choose the detail types and statuses for which you want to receive notifications. For example, to select events for automations that fail choose EC2 Automation Execution Status-change Notification and Failed.
6. Choose Add targets.
7. In the Select target type list, choose a target type. For information about the different types of targets, see the corresponding AWS Help documentation.
8. Choose Configure details.
9. Specify the rule details, and then choose Create rule.

**3.3.4. State Manager**

Supported Events Include:
* State change for an association
* State change for an instance association.

**3.3.5. Configuration Compliance**

Supported Events Include:
* State change for association compliance.
* State change for instance patch compliance.

You can also configure CloudWatch Events to perform an action in response to Configuration Compliance events. For example, if one or more instances fail to install Critical patch updates or run an association that installs anti-virus software, then you can configure CloudWatch to run the `AWS-RunPatchBaseline` document or the `AWS-RefreshAssocation` document when the Configuration Compliance event occurs.

**Configure Configuration Compliance as the target of a CloudWatch event (console)**
1. In the left navigation pane, choose Events, and then choose Create rule.
2. Choose Event Pattern. Event Pattern lets you build a rule that generates events for specific actions in AWS services.
3. In the Service Name field, choose EC2 Simple Systems Manager (SSM)
4. In the Event Type field, choose Configuration Compliance.
5. Choose Add target.
6. In the Select target type list, choose SSM Run Command.
7. In the Document list, choose an SSM document to run when your target is invoked. For example, choose AWS-RunPatchBaseline for a non-compliant patch event, or choose AWS-RefreshAssociation for a non-compliant association event.
8. Specify information for the remaining fields and parameters.
9. Choose Configure details and complete the wizard.

**3.3.6. Maintenance Window**

Supported Events Include:
* State change for a maintenance window (enabled or disabled)
* Change in a maintenance window target registration.
* Change in a maintenance window task registration.
* State change for a maintenance window execution.
* State change for a maintenance window task execution.
* State change for a maintenance window task target invocation.

**3.3.7. Parameter Store**

Supported Events Include:
* A parameter is created, updated, or deleted, or a label is attached or moved from one version to another (detail-type: `"Parameter Store Change"`).
* A parameter has expired or been deleted, its expiration date is approaching, or its value hasn't been changed for a specified period of time (detail-type: `"Parameter Store Policy Action"`).

**Configure CloudWatch Events for Systems Manager parameters**
1. In the left navigation pane, choose Events, and then choose Create rule.
2. Under Event Source, verify that Event Pattern is selected.
3. Above the Event Pattern Preview field, choose Edit.
4. Replace the content in the edit box with the following:
    ```json
    {
        "source": [
            "aws.ssm"
        ],
        "detail-type": [
            "Parameter Store Change"
        ],
        "detail": {
            "name": [
                "parameter-1-name",
                "/parameter-2-name/level-2",
                "/parameter-3-name/level-2/level-3"
            ],
            "operation": [
                "Create",
                "Update",
                "Delete",
                "LabelParameterVersion"
            ]
        }
    }
    ```
5. Modify the contents for the parameters and the operations you want to take action on
    * For example, the following content means an action is taken when either of the parameters named `/Oncall` and `/Project/Teamlead` are updated:
    ```json
    {
        "source": [
            "aws.ssm"
        ],
        "detail-type": [
            "Parameter Store Change"
        ],
        "detail": {
            "name": [
                "/Oncall",
                "/Project/Teamlead"
            ],
            "operation": [
                "Update"
            ]
        }
    }
    ```
6. Choose Save.
7. For Targets, choose Add targets.
8. In the Targets list, choose a target type. For example, choose Lambda function or SNS topic.
9. Expand Configure input and choose an option. Then provide any other configuration details required by the target type you selected.
10. Scroll to the bottom of the page, if necessary, and then choose Configure details.
11. Provide a name and (optional) description for the CloudWatch Events rule. Leave the Enabled box selected to make the rule active immediately.
12. Choose Create rule.

To create CloudWatch Events rules that invoke targets based on events that happen to one or more parameter policies in your AWS account, see [Configuring CloudWatch Events for parameter policies](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-cwe.html#cwe-parameter-policy-status). When you create an advanced parameter, you specify when a parameter expires, when to receive notification before a parameter expires, and how long to wait before notification should be sent that a parameter hasn't changed, You set up notification for these events using the following procedure.

**3.3.8. Inventory**

You can configure Amazon CloudWatch Events to create an event anytime a user deletes custom inventory. CloudWatch Events offers three types of events for custom inventory delete operations.

|Supported Events Include|Description|
|------------------|-------------------------|
|Deletion of custom inventory item on an instance|If the custom inventory for a specific managed instance was successfully deleted or not|
|Availability of a delete action summary|A summary of the delete action|
|A disabled custom inventory type is detected|A warning event if a user called the `PutInventory` API action for a custom inventory type version that was previously-disabled|

**Delete action for an instance**
```json
{
   "version":"0",
   "id":"998c9cde-56c0-b38b-707f-0411b3ff9d11",
   "detail-type":"Inventory Resource State Change",
   "source":"aws.ssm",
   "account":"478678815555",
   "time":"2018-05-24T22:24:34Z",
   "region":"us-east-1",
   "resources":[
      "arn:aws:ssm:us-east-1:478678815555:managed-instance/i-0a5feb270fc3f0b97"
   ],
   "detail":{
      "action-status":"succeeded",
      "action":"delete",
      "resource-type":"managed-instance",
      "resource-id":"i-0a5feb270fc3f0b97",
      "action-reason":"",
      "type-name":"Custom:MyInfo"
   }
}
```
**Delete action summary**
```json
{
   "version":"0",
   "id":"83898300-f576-5181-7a67-fb3e45e4fad4",
   "detail-type":"Inventory Resource State Change",
   "source":"aws.ssm",
   "account":"478678815555",
   "time":"2018-05-24T22:28:25Z",
   "region":"us-east-1",
   "resources":[

   ],
   "detail":{
      "action-status":"succeeded",
      "action":"delete-summary",
      "resource-type":"managed-instance",
      "resource-id":"",
      "action-reason":"The delete for type name Custom:MyInfo was completed. The deletion summary is: {\"totalCount\":2,\"remainingCount\":0,\"summaryItems\":[{\"version\":\"1.0\",\"count\":2,\"remainingCount\":0}]}",
      "type-name":"Custom:MyInfo"
   }
}
```
**Warning for disabled custom inventory type**
```json
{
   "version":"0",
   "id":"49c1855c-9c57-b5d7-8518-b64aeeef5e4a",
   "detail-type":"Inventory Resource State Change",
   "source":"aws.ssm",
   "account":"478678815555",
   "time":"2018-05-24T22:46:58Z",
   "region":"us-east-1",
   "resources":[
      "arn:aws:ssm:us-east-1:478678815555:managed-instance/i-0ee2d86a2cfc371f6"
   ],
   "detail":{
      "action-status":"failed",
      "action":"put",
      "resource-type":"managed-instance",
      "resource-id":"i-0ee2d86a2cfc371f6",
      "action-reason":"The inventory item with type name Custom:MyInfo was sent with a disabled schema version 1.0. You must send a version greater than 1.0",
      "type-name":"Custom:MyInfo"
   }
}
```

### 4. Patch Management and Vulnerability Management
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.IP-12|A vulnerability management plan is developed and implemented|
|DE.CM-8|Vulnerability scans are performed|

**Why?** Vulnerabilities are weaknesses in software that can expose a system to unwanted malicious activity. By applying regular patches and performing regular vulnerability scans, you help to ensure the safety and integrity of a system.

**How?** AWS Systems Manager Patch Manager automates the process of patching managed instances with both security related and other types of updates. The primary focus of Patch Manager is on installing operating systems security-related updates on instances. By default, Patch Manager doesn't install all available patches, but rather a smaller set of patches focused on security. You can use Patch Manager to apply patches for both operating systems and applications. In order for AWS Systems Manager to communicate with your instance, you will need to install the SSM Agent on the instance.

Patch Manager uses *patch baselines*, which include rules for auto-approving patches within days of their release, as well as a list of approved and rejected patches. You can install patches on a regular basis by scheduling patching to run as a Systems Manager maintenance window task. You can also install patches individually or to large groups of instances by using Amazon EC2 tags. You can add tags to your patch baselines themselves when you create or update them.

**4.1. Supported Operating Systems**

The Patch Manager capability does not support all the same operating systems versions that are supported by other AWS Systems Manager capabilities. 

1. Supported Linux Operating Systems and Versions
    * Amazon Linux 2012.03 - 2018.03
    * Amazon Linux 2 2 - 2.0
    
2. Supported Windows OS Versions
    * Windows Server 2008 through Windows Server 2019, including R2 versions

**4.2. Creating a patch baseline**

Below example is to create a patch baseline that: 
* Approves all critical and important security updates for Windows Server 2012 R2 two days after they are released.
* Patches have also been specified for the Approved and Rejected patch lists. 
* In addition, the patch baseline has been tagged to indicate that it is for a production environment.

```bash
aws ssm create-patch-baseline \
    --name "Windows-Server-2012R2" \
    --tags "Key=Environment,Value=Production" \
    --description "Windows Server 2012 R2, Important and Critical security updates" \
    --approved-patches "KB2032276,MS10-048" \
    --rejected-patches "KB2124261" \
    --rejected-patches-action "ALLOW_AS_DEPENDENCY" \
    --approval-rules "PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=MSRC_SEVERITY,Values=[Important,Critical]},{Key=CLASSIFICATION,Values=SecurityUpdates},{Key=PRODUCT,Values=WindowsServer2012R2}]},ApproveAfterDays=2}]"
```
**4.2. Creating a patch baseline with custom repositories for different OS versions**

This applies to Linux only. 

Below example shows how to specify the patch repository to use for a particular version of the Amazon Linux operating system. This sample uses a source repository enabled by default on Amazon Linux 2017.09, but could be adapted to a different source repository that you have configured for an instance.

This example uses the `--cli-input-json` option with additional options stored in an external JSON file

1. Create a JSON file with a name like `my-patch-repository.json` and add the following content to it
```json
{
    "Description": "My patch repository for Amazon Linux 2017.09",
    "Name": "Amazon-Linux-2017.09",
    "OperatingSystem": "AMAZON_LINUX",
    "ApprovalRules": {
        "PatchRules": [
            {
                "ApproveAfterDays": 7,
                "EnableNonSecurity": true,
                "PatchFilterGroup": {
                    "PatchFilters": [
                        {
                            "Key": "SEVERITY",
                            "Values": [
                                "Important",
                                "Critical"
                            ]
                        },
                        {
                            "Key": "CLASSIFICATION",
                            "Values": [
                                "Security",
                                "Bugfix"
                            ]
                        },
                        {
                            "Key": "PRODUCT",
                            "Values": [
                                "AmazonLinux2017.09"
                            ]
                        }
                    ]
                }
            }
        ]
    },
    "Sources": [
        {
            "Name": "My-AL2017.09",
            "Products": [
                "AmazonLinux2017.09"
            ],
            "Configuration": "[amzn-main] \nname=amzn-main-Base\nmirrorlist=http://repo./$awsregion./$awsdomain//$releasever/main/mirror.list //nmirrorlist_expire=300//nmetadata_expire=300 \npriority=10 \nfailovermethod=priority \nfastestmirror_enabled=0 \ngpgcheck=1 \ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-amazon-ga \nenabled=1 \nretries=3 \ntimeout=5\nreport_instanceid=yes"
        }
    ]
}
```

2. In the directory where you saved the file, run the following command

```bash
aws ssm create-patch-baseline --cli-input-json file://my-patch-repository.json
```

For additional Patch Manager examples, see [Working with Patch Manager (AWS CLI)](https://docs.aws.amazon.com/systems-manager/latest/userguide/patch-manager-cli-commands.html) or [Working with Patch Manager (console)](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-patch-working.html). 

## Detective
### 1. Establish Config rules to monitor for deviations from normal configuration
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|DE.AE-1|A baseline of network operations and expected data flows for users and systems is established and managed|
|DE.AE-2|Detected events are analyzed to understand attack targets and methods|
|DE.AE-3|Event data are collected and correlated from multiple sources and sensors|
|DE.CM-1|The network is monitored to detect potential cybersecurity events|
|DE.CM-3|Personnel activity is monitored to detect potential cybersecurity events|
|DE.CM-7|Monitoring for unauthorized personnel, connections, devices, and software is performed|

**Why?** AWS Config enables you to assess, audit, and evaluate the configurations of your AWS resources. AWS Config monitors resource configurations, allowing you to evaluate the recorded configurations against the desired secure configurations 

**How?** Using AWS Config, you can review changes in configurations and relationships between AWS resources, investigate detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines. This can help you simplify compliance auditing, security analysis, change management, and operational troubleshooting. For more information, see [Setting Up AWS Config with the Console](https://docs.aws.amazon.com/config/latest/developerguide/gs-console.html). When specifying the resource types to record, ensure that you include Systems Manager resources.

## Respond/Recover
### 1. Utilize Amazon EventBridge for automated incident response
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|RS.AN-1|Notifications from detection systems are investigated|
|RS.AN-2|The impact of the incident is understood|
|RS.AN-3|Forensics are performed|
|RS.AN-4|Incidents are categorized consistent with response plans|
|RS.AN-5|Processes are established to receive, analyze and respond to vulnerabilities disclosed to the organization from internal and external sources (e.g. internal testing, security bulletins, or security researchers)|

**Why?** Using Amazon EventBridge, you can automatically report and respond to incidents, including actions taken on worker nodes, or EMR API Calls via CloudTrail.

**How?** For various incident types, an appropriate response rule should be determined and added to EventBridge. Depending on the organization's Incident Response Plan, there may be need for human interaction in some cases, or fully automated remediation in other cases.

For example, EventBridge lets you set up rules to detect when changes happen to AWS resources. You can create a rule to detect when a user in your organization starts or ends a session, and then, for example, receive a notification through Amazon SNS about the event.

**Monitoring session activity using Amazon EventBridge (console)**

EventBridge support for Session Manager relies on records of API actions that were recorded by CloudTrail. (You can use CloudTrail integration with EventBridge to respond to most AWS Systems Manager events.)

The following steps outline how to trigger notifications through Amazon Simple Notification Service (Amazon SNS) when a Session Manager API event occurs, such as StartSession.

1. Create an Amazon SNS topic to use for sending notifications when the Session Manager event occurs that you want to track.
    * For more information, see [Create](https://docs.aws.amazon.com/sns/latest/dg/CreateTopic.html) a Topic in the Amazon Simple Notification Service Developer Guide.
2. Create an EventBridge rule to invoke the Amazon SNS target for the type of Session Manager event you want to track.
    * For information about how to create the rule, see [Creating an EventBridge Rule That Triggers on an Event from an AWS Resource](https://docs.aws.amazon.com/eventbridge/latest/userguide/create-eventbridge-rule.html) in the Amazon EventBridge User Guide.
3. As you follow the steps to create the rule, make the following selections:
    * For Service Name, choose EC2 Simple Systems Manager (SSM).
    * For Event Type, choose AWS API Call via CloudTrail.
    * Choose Specific operation(s), and then enter the Session Manager command or commands (one at a time) you want to receive notifications for. You can choose StartSession, ResumeSession, and TerminateSession. (EventBridge doesn't support `Get*`, `List*`, and `Describe*` commands.)
    * ForTargets, choose SNS topic. For Topic, choose the name of the Amazon SNS topic you created in Step 1

For additional details, see [Monitoring session activity using Amazon EventBridge](https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-logging-auditing.html)

## Capital Group Control Statements
1. All Data-at-rest must be encrypted and use a CG BYOK encryption key.
2. All Data-in-transit must be encrypted using certificates using CG Certificate Authority.
3. Keys storied in a Key Management System (KMS) should be created by Capital Group's hardware security module (HSM) and are a minimum of AES-256.
4. AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.
5. Local AWS IAM accounts are restricted to services and no user accounts are to be provisioned including IaaS resources.
6. Any AWS service used by CG should not be directly available to the Internet and the default route is always the CG gateway.
7. Use of AWS IAM accounts are restricted to CG networks.
8. Local IAM secrets are rotated every 90 days, including accounts IaaS resources.
9. Encryption keys are rotated annually.
10. Root accounts must have 2FA/MFA enabled.
