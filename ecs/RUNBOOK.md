<img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png" alt="AWS" width="250"/>

# Amazon Elastic Container Service (ECS) - Security Runbook <!-- omit in toc -->
## Capgroup Cybersecurity Control Alignment <!-- omit in toc -->

**Generated By:**  
[Rob Goss (RMG)](https://cgweb3/profile/RMG)
<br>
[Srinath Medala (SRGM)](https://cgweb3/profile/SRGM)
<br>
Security Engineering

**Last Update:** *09/24/2021*

## Table of Contents <!-- omit in toc -->
- [Overview](#overview)
- [Cloud Security Requirements](#cloud-security-requirements)
  - [1. Implement least privilege IAM Roles for Tasks](#1-implement-least-privilege-iam-roles-for-tasks)
  - [2. Using Elastic Container Registry (ECR) for storing and retrieving Docker images](#2-using-elastic-container-registry-ecr-for-storing-and-retrieving-docker-images)
  - [3. Configuring VPC endpoints for ECS](#3-configuring-vpc-endpoints-for-ecs)
  - [4. Using AWS Systems Manager Parameter Store for referencing both sensitive and non sensitive data](#4-using-aws-systems-manager-parameter-store-for-referencing-both-sensitive-and-non-sensitive-data)
  - [5. Using AWS Secrets Manager for referencing sensitive data](#5-using-aws-secrets-manager-for-referencing-sensitive-data)
  - [6. Using the awslogs Log Driver](#6-using-the-awslogs-log-driver)
  - [7. Creating a CloudTrail to log ECS API calls](#7-creating-a-cloudtrail-to-log-ecs-api-calls)
  - [8. Enable VPC Flow Logs for ECS Cluster VPC (EC2 Launch Types Only)](#8-enable-vpc-flow-logs-for-ecs-cluster-vpc-ec2-launch-types-only)
  - [9. Scan images for Vulnerabilities](#9-scan-images-for-vulnerabilities)
  - [10. Remove special permissions from images](#10-remove-specal-permissions-from-images)
  - [11. Run containers as non-root users](#11-run-containers-as-non-root-users)
  - [12. Use a read-only root file system](#12-use-a-read-only-file-system)
  - [13. ECS data in transit must enforce TLS with version 1.2 or higher](#13-ecs-data-in-transit-must-enforce-tls-with-version-1.2-or-higher)
  - [14. Make sure ECS Task network interface does not have public IP address](#14-make-sure-ecs-task-network-interface-does-not-have-public-ip-address)
  - [15. Use always Fargate launch type in ECS Cluster with version 1.4 and above](#15-use-always-fargate-launch-type-in-ecs-cluster-with-version-1.4-and-above)
- [Operational Best Practices](#operational-best-practices)  
  - [1. Utilizing AWS CloudWatch Container Insights](#1-utilizing-aws-cloudwatch-container-insights)
  - [2. ECS Resources are tagged according to CG Standards](#4-ecs-resources-are-tagged-according-to-cg-standards)
  - [3. Configure tasks with CPU and Memory limits (Amazon EC2)](#5-configure-tasks-with-cpu-and-memory-limits) 
- [Endnotes](#Endnotes)
- [Capital Group Glossary](#Capital-Group-Glossary)
  <br><br>
  


## Overview
Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service that helps you easily deploy, manage, and scale containerized applications. It deeply integrates with the rest of the AWS platform to provide a secure and easy-to-use solution for running container workloads in the cloud and now on your infrastructure with Amazon ECS Anywhere.


AWS provides a number of security features for Amazon Elastic Container Service (ECS) which help you comply with the NIST Cybersecurity Framework. The following Runbook will Provide implementation details to deploy the Amazon Elastic Conatainer service in accordance with NIST CSF and service applicable security controls.This runbook in its continued development will provide support to the automated configuration of hardening workloads an processes. 

These NIST Controls and Subcategories are not applicable to this service: PR.AT, PR.MA, PR.IP  (Unless stated), PR.AC-2, PR.AC-3, PR.DS-3, PR.DS-8, PR.PT-2, PR.PT-5, DE.DP1, DE.DP-2. DE.DP-3, DE.CM-3, DE.AE-5, RC, RS.MI.

These capital group control statements are not applicable to the ECS service: 5,7,8,9,10. 

## Cloud Security Requirements
<img src="/docs/img/Prevent.png" width="50">

### 1. Implement least privilege IAM Roles for Tasks

**Capital Group Controls:** 
<br>
|Control Statement|Description|
|------|----------------------|
| CS0012298 | Access to change cloud identity access and service control policies is restricted to authorized cloud administrative personnel. |
| CS0012299 | Access to change cloud resource-based access policies is restricted to authorized personnel. |

<br>

**Why?**

Based on IAM least privilege access model, CG Security Team recommends each task should have its own IAM role based on the access it needs. Outside various available options of IAM Roles, CG recommends to use the following 'Task Execution Role'.The task execution role is used to grant the Amazon ECS container agent permission to call specific AWS API actions on your behalf. For example, when you use AWS Fargate, Fargate needs an IAM role that allows it to pull images from Amazon ECR and write logs to CloudWatch Logs. An IAM role is also required when a task references a secret that's stored in AWS Secrets Manager, such as an image pull secret.

Benefits of Using IAM Roles for Tasks
+ **Credential Isolation:** A container can only retrieve credentials for the IAM role that is defined in the task definition to which it belongs; a container never has access to credentials that are intended for another container that belongs to another task\.
+ **Authorization:** Unauthorized containers cannot access IAM role credentials defined for other tasks\.
+ **Auditability:** Access and event logging is available through CloudTrail to ensure retrospective auditing\. Task credentials have a context of `taskArn` that is attached to the session, so CloudTrail logs show which task is using which role\.

**How?**

Creating the task execution IAM role

If your account does not already have a task execution role, use the following steps to create the role.

To create a task execution IAM role (AWS Management Console)

1. Open the IAM console at https://console.aws.amazon.com/iam/.

2. In the navigation pane, choose Roles, Create role.

3. In the Select type of trusted entity section, choose AWS service, Elastic Container Service.

4. For Select your use case, choose Elastic Container Service Task, then choose Next: Permissions.

5. In the Attach permissions policy section, search for AmazonECSTaskExecutionRolePolicy, select the policy, and then choose Next: Tags.

6. For Add tags (optional), specify any custom tags to associate with the policy and then choose Next: Review.

7. For Role name, type ecsTaskExecutionRole and choose Create role.

To create a task execution IAM role (AWS CLI)

1. Create a file named ecs-tasks-trust-policy.json that contains the trust policy to use for the IAM role. The file should contain the following:

```
  {
    "Version": "2012-10-17",
    "Statement": [
      {
        "Sid": "",
        "Effect": "Allow",
        "Principal": {
          "Service": "ecs-tasks.amazonaws.com"
        },
        "Action": "sts:AssumeRole"
      }
    ]
  }
```  
2. Create an IAM role named ecsTaskExecutionRole using the trust policy created in the previous step.

```
  aws iam create-role \
        --role-name ecsTaskExecutionRole \
        --assume-role-policy-document file://ecs-tasks-trust-policy.json
```        
3. Attach the AWS managed AmazonECSTaskExecutionRolePolicy policy to the ecsTaskExecutionRole role. This policy provides

```
aws iam attach-role-policy \
      --role-name ecsTaskExecutionRole \
      --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
```

## 2. Using Elastic Container Registry (ECR) for storing and retrieving Docker images

Capital Group:
|Control Statement|Description|
|------|----------------------|
|[CS0012300](https://capitalgroup.service-now.com/cg_grc?sys_id=80df48c01bac20506a50beef034bcb47&table=sn_compliance_policy_statement&id=cg_grc_action_item_details&view=sp)|Cloud products and services must be deployed on private subnets and public access must be disabled for these services.| 


**Why?**

CG's public access requirements for cloud state that resources should be secured in environments and not be publicly accessible. ECR is a fully managed container registry that makes it easy to store, manage, share and deploy container images and artifacts in a secure manner. Amazon ECR hosts your images in a highly available and high-performance architecture, allowing you to deploy images for your container applications reliably. You can share container software privately within Capital Group or publicly worldwide for anyone to discover and download.

**How?**

### Using Amazon ECR Images with Amazon ECS

You can use your ECR images with Amazon ECS, but you need to satisfy the following prerequisites\.
+ Your container instances must be using at least version 1\.7\.0 of the Amazon ECS container agent\. The latest version of the Amazon ECS–optimized AMI supports ECR images in task definitions\. For more information, including the latest Amazon ECS–optimized AMI IDs, see [Amazon ECS Container Agent Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-versions.html) in the *Amazon Elastic Container Service Developer Guide*\.
+ The Amazon ECS container instance role \(`ecsInstanceRole`\) that you use with your container instances must possess the following IAM policy permissions for Amazon ECR\.

```
  {
      "Version": "2012-10-17",
      "Statement": [
          {
              "Effect": "Allow",
              "Action": [
                  "ecr:BatchCheckLayerAvailability",
                  "ecr:BatchGetImage",
                  "ecr:GetDownloadUrlForLayer",
                  "ecr:GetAuthorizationToken"
              ],
              "Resource": "*"
          }
      ]
  }
```

  If you use the `AmazonEC2ContainerServiceforEC2Role` managed policy for your container instances, then your role has the proper permissions\. To check that your role supports Amazon ECR, see [Amazon ECS Container Instance IAM Role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html) in the *Amazon Elastic Container Service Developer Guide*\.
+ In your ECS task definitions, make sure that you are using the full `registry/repository:tag` naming for your ECR images\. For example, `aws_account_id.dkr.ecr.region.amazonaws.com``/my-web-app:latest`\.
  The following task definition snippet shows the syntax you would use to specify a container image hosted in Amazon ECR in your Amazon ECS task definition.

```
  {
      "family": "task-definition-name",
      ...
      "containerDefinitions": [
          {
              "name": "container-name",
              "image": "aws_account_id.dkr.ecr.region.amazonaws.com/my-repository:latest",
              ...
          }
      ],
      ...
  }
```

## 3. Configuring VPC Endpoints for ECS 

Capital Group:
|Control Statement|Description|
|------|----------------------|
|[CS0012300](https://capitalgroup.service-now.com/cg_grc?sys_id=80df48c01bac20506a50beef034bcb47&table=sn_compliance_policy_statement&id=cg_grc_action_item_details&view=sp)|Cloud products and services must be deployed on private subnets and public access must be disabled for these services.| 

**Why?**

In order to use securely communicate with AWS Services like S3, ECR, without accessing public internet, VPC Endpoints using AWS Privatelink provides a way to restrict the traffic from VPC to AWS Service using private IP addresses. 

### Amazon ECS Interface VPC Endpoints \(AWS PrivateLink\)

You can improve the security posture of your VPC by configuring Amazon ECS to use an interface VPC endpoint\. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access Amazon ECS APIs by using private IP addresses\. PrivateLink restricts all network traffic between your VPC and Amazon ECS to the Amazon network\. You don't need an internet gateway, a NAT device, or a virtual private gateway\.

You're not required to configure PrivateLink, but we recommend it\. For more information about PrivateLink and VPC endpoints, see [Accessing Services Through AWS PrivateLink](https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html#what-is-privatelink)\.

**How?**

### Pre requisites for Amazon ECS VPC Endpoints

Before you set up interface VPC endpoints for Amazon ECS, be aware of the following considerations:
+ Tasks using the Fargate launch type don't require the interface VPC endpoints for Amazon ECS, but you might need interface VPC endpoints for Amazon ECR or Amazon CloudWatch Logs described in the following points\.
  + To allow your tasks to pull private images from Amazon ECR, you must create the interface VPC endpoints for Amazon ECR\. For more information, see [Interface VPC Endpoints \(AWS PrivateLink\)](https://docs.aws.amazon.com/AmazonECR/latest/userguide/vpc-endpoints.html) in the *Amazon Elastic Container Registry User Guide*\.
**Important**  
If you configure Amazon ECR to use an interface VPC endpoint, you can create a task execution role that includes condition keys to restrict access to a specific VPC or VPC endpoint\. 
  + If your VPC doesn't have an internet gateway and your tasks use the `awslogs` log driver to send log information to CloudWatch Logs, you must create an interface VPC endpoint for CloudWatch Logs\. For more information, see [Using CloudWatch Logs with Interface VPC Endpoints](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/cloudwatch-logs-and-interface-VPC.html) in the *Amazon CloudWatch Logs User Guide*\.
+ Tasks using the EC2 launch type require that the container instances that they're launched on to run at least version `1.25.1` of the Amazon ECS container agent\. 
+ VPC endpoints currently don't support cross\-Region requests\. Ensure that you create your endpoint in the same Region where you plan to issue your API calls to Amazon ECS\.
+ VPC endpoints only support Amazon\-provided DNS through Amazon Route 53\. If you want to use your own DNS, you can use conditional DNS forwarding\. For more information, see [DHCP Options Sets](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_DHCP_Options.html) in the *Amazon VPC User Guide*\.
+ The security group attached to the VPC endpoint must allow incoming connections on port 443 from the private subnet of the VPC\.
+ Controlling access to Amazon ECS by attaching an endpoint policy to the VPC endpoint isn't currently supported\. By default, full access to the service will be allowed through the endpoint\. For more information, see [Controlling Access to Services with VPC Endpoints](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html) in the *Amazon VPC User Guide*\.

### Creating the VPC Endpoints for Amazon ECS

To create the VPC endpoint for the Amazon ECS service, use the [Creating an Interface Endpoint](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.html#create-interface-endpoint) procedure in the *Amazon VPC User Guide* to create the following endpoints\. 
### Creating an interface endpoint
To create an interface endpoint, you must specify the VPC in which to create the interface endpoint, and the service to which to establish the connection\. 


#### [ Console ]

**To create an interface endpoint to an AWS service using the console**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

2. In the navigation pane, choose **Endpoints**, **Create Endpoint**\.

3. For **Service category**, ensure that **AWS services** is selected\.

4. For **Service Name**, choose the service to which to connect\. For **Type**, ensure that it indicates **Interface**\.

5. Complete the following information and then choose **Create endpoint**\.
   + For **VPC**, select a VPC in which to create the endpoint\.
   + For **Subnets**, select the subnets \(Availability Zones\) in which to create the endpoint network interfaces\.

     Not all Availability Zones may be supported for all AWS services\.
   + To enable private DNS for the interface endpoint, for **Enable Private DNS Name**, select the check box\.

     This option is enabled by default\. To use the private DNS option, the following attributes of your VPC must be set to `true`: `enableDnsHostnames` and `enableDnsSupport`\. 
   + For **Security group**, select the security groups to associate with the endpoint network interfaces\.
   + \(Optional\) Add or remove a tag\.

     \[Add a tag\] Choose **Add tag** and do the following:
     + For **Key**, enter the key name\.
     + For **Value**, enter the key value\.

     \[Remove a tag\] Choose the delete button \(“x”\) to the right of the tag’s Key and Value\.


## 4. Using AWS Systems Manager Parameter Store for referencing both sensitive and non sensitive data

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

For non sensitive information use Parameter Store for environmental variables. The advantge of using Parameter store is decoupling the environmental variables from task definitions. Environment variables can be updated without touching the task definition. When specifying sensitive information make sure to encrypt the key and value pair. 

**How?**

Amazon ECS enables you to inject sensitive data into your containers by storing your sensitive data in AWS Systems Manager Parameter Store parameters and then referencing them in your container definition.

### Pre requisites for specifying sensitive data Using Systems Manager Parameter Store

The following should be considered when specifying sensitive data for containers using Systems Manager Parameter Store parameters.

  + For tasks that use the Fargate launch type, this feature requires that your task use platform version 1.3.0 or later.

  + Sensitive data is injected into your container when the container is initially started. If the secret or Parameter Store parameter is subsequently updated or rotated, the container will not receive the updated value automatically. You must either launch a new task or if your task is part of a service you can update the service and use the Force new deployment option to force the service to launch a fresh task.

### Required IAM Permissions for Amazon ECS Secrets

To provide access to the AWS Systems Manager Parameter Store parameters that you create, manually add the following permissions as an inline policy to the task execution role. For more information, see Adding and Removing IAM Policies.

+ ssm:GetParameters—Required if you are referencing a Systems Manager Parameter Store parameter in a task definition.

+ secretsmanager:GetSecretValue—Required if you are referencing a Secrets Manager secret either directly or if your Systems Manager Parameter Store parameter is referencing a Secrets Manager secret in a task definition.

+ kms:Decrypt—Required only if your secret uses a custom KMS key and not the default key. The ARN for your custom key should be added as a resource.

The following example inline policy adds the required permissions:

```
  {
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow",
        "Action": [
          "ssm:GetParameters",
          "secretsmanager:GetSecretValue",
          "kms:Decrypt"
        ],
        "Resource": [
          "arn:aws:ssm:<region>:<aws_account_id>:parameter/<parameter_name>",
          "arn:aws:secretsmanager:<region>:<aws_account_id>:secret:<secret_name>",
          "arn:aws:kms:<region>:<aws_account_id>:key/<key_id>"
        ]
      }
    ]
  }
```
To use this feature, you must have the Amazon ECS task execution role and reference it in your task definition. This allows the container agent to pull the necessary AWS Systems Manager resources  

### Injecting sensitive data as an environment variable

Within your container definition, specify secrets with the name of the environment variable to set in the container and the full ARN of the Systems Manager Parameter Store parameter containing the sensitive data to present to the container.

The following is a snippet of a task definition showing the format when referencing a Systems Manager Parameter Store parameter. If the Systems Manager Parameter Store parameter exists in the same Region as the task you are launching, then you can use either the full ARN or name of the parameter. If the parameter exists in a different Region, then the full ARN must be specified.

```
  {
    "containerDefinitions": [{
      "secrets": [{
        "name": "environment_variable_name",
        "valueFrom": "arn:aws:ssm:region:aws_account_id:parameter/parameter_name"
      }]
    }]
  }
```  


## 5. Using AWS Secrets Manager for referencing sensitive data

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

Amazon ECS enables you to inject sensitive data into your containers by storing your sensitive data in AWS Secrets Manager secrets and then referencing them in your container definition. Sensitive data stored in Secrets Manager secrets can be exposed to a container as environment variables or as part of the log configuration.When you inject a secret as an environment variable, you can specify a JSON key or version of a secret to inject. This process helps you control the sensitive data exposed to your container. 

**How?**

### Pre requisites for specifying sensitive data using Secrets Manager

The following should be considered when using Secrets Manager to specify sensitive data for containers.

  + For tasks that use the Fargate launch type, the following should be considered:
    + It is only supported to inject the full contents of a secret as an environment variable. Specifying a specific JSON key or version is not supported at this time.
     + To inject the full content of a secret as an environment variable or in a log configuration, you must use platform version 1.3.0 or later. For information, see AWS Fargate Platform Versions.

  +  Sensitive data is injected into your container when the container is initially started. If the secret is subsequently updated or rotated, the container will not receive the updated value automatically. You must either launch a new task or if your task is part of a service you can update the service and use the Force new deployment option to force the service to launch a fresh task.

### Required IAM Permissions for Amazon ECS Secrets

To use this feature, you must have the Amazon ECS task execution role and reference it in your task definition. This allows the container agent to pull the necessary Secrets Manager resources. For more information, see Amazon ECS Task Execution IAM Role.
Important

To provide access to the Secrets Manager secrets that you create, manually add the following permissions as an inline policy to the task execution role. For more information, see Adding and Removing IAM Policies.

  +  secretsmanager:GetSecretValue–Required if you are referencing a Secrets Manager secret.

  +  kms:Decrypt–Required only if your secret uses a custom KMS key and not the default key. The ARN for your custom key should be added as a resource.

The following example inline policy adds the required permissions.
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "secretsmanager:GetSecretValue",
        "kms:Decrypt"
      ],
      "Resource": [
        "arn:aws:secretsmanager:<region>:<aws_account_id>:secret:<secret_name>",
        "arn:aws:kms:<region>:<aws_account_id>:key/<key_id>"
      ]
    }
  ]
}
```
### Injecting Sensitive Data as an Environment Variable

Within your container definition, you can specify the following:

  + The secrets object containing the name of the environment variable to set in the container

  + The Amazon Resource Name (ARN) of the Secrets Manager secret

   + Additional parameters that contain the sensitive data to present to the container

The following example shows the full syntax that must be specified for the Secrets Manager secret.

```
arn:aws:secretsmanager:region:aws_account_id:secret:secret-name:json-key:version-stage:version-id
```

### Example Container Definitions

The following examples show ways in which you can reference Secrets Manager secrets in your container definitions.

**Example referencing a full secret**

The following is a snippet of a task definition showing the format when referencing the full text of a Secrets Manager secret.

```
{
  "containerDefinitions": [{
    "secrets": [{
      "name": "environment_variable_name",
      "valueFrom": "arn:aws:secretsmanager:region:aws_account_id:secret:secret_name-AbCdEf"
    }]
  }]
}

```
**Example referencing a specific key within a secret**

The following shows an example output from a get-secret-value command that displays the contents of a secret along with the version staging label and version ID associated with it.

```
{
    "ARN": "arn:aws:secretsmanager:region:aws_account_id:secret:appauthexample-AbCdEf",
    "Name": "appauthexample",
    "VersionId": "871d9eca-18aa-46a9-8785-981dd39ab30c",
    "SecretString": "{\"username1\":\"password1\",\"username2\":\"password2\",\"username3\":\"password3\"}",
    "VersionStages": [
        "AWSCURRENT"
    ],
    "CreatedDate": 1581968848.921
}
```
Reference a specific key from the previous output in a container definition by specifying the key name at the end of the ARN.
```
{
  "containerDefinitions": [{
    "secrets": [{
      "name": "environment_variable_name",
      "valueFrom": "arn:aws:secretsmanager:region:aws_account_id:secret:appauthexample-AbCdEf:username1::"
    }]
  }]
}
```


## 6. Using the awslogs Log Driver

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.|

**Why?**

You need need use awslogs log driver in order send all the logs from Fargae and EC2 Instance type to centralized logging location. These logs are used are used but the CG Security Engineering Teams to detect malicious activity.

**How?**

You can configure the containers in your tasks to send log information to CloudWatch Logs\. If you are using the Fargate launch type for your tasks, this allows you to view the logs from your containers\. 

### Enabling the awslogs Log Driver for Your Containers

If you are using the Fargate launch type for your tasks, all you need to do to enable the `awslogs` log driver is add the required `logConfiguration` parameters to your task definition\.

### Creating a Log Group

The `awslogs` log driver can send log streams to an existing log group in CloudWatch Logs or it can create a new log group on your behalf\. The AWS Management Console provides an auto\-configure option which creates a log group on your behalf using the task definition family name with `ecs` as the prefix\. Alternatively, you can manually specify your log configuration options and specify the `awslogs-create-group` option with a value of `true` which will create the log groups on your behalf\.

**Note**  
To use the `awslogs-create-group` option to have your log group created, your IAM policy must include the `logs:CreateLogGroup` permission\.

### Using the Auto\-configuration Feature to Create a Log Group

When registering a task definition in the Amazon ECS console, you have the option to allow Amazon ECS to auto\-configure your CloudWatch logs\. This option creates a log group on your behalf using the task definition family name with `ecs` as the prefix\.

**To use log group auto\-configuration option in the Amazon ECS console**

1. Open the Amazon ECS console at [https://console\.aws\.amazon\.com/ecs/](https://console.aws.amazon.com/ecs/)\.
2. In the left navigation pane, choose **Task Definitions**, **Create new Task Definition**\.
3. Select your compatibility option and choose **Next Step**\.
4. Choose **Add container**\.
5. In the **Storage and Logging** section, for **Log configuration**, choose **Auto\-configure CloudWatch Logs**\.
6. Enter your awslogs log driver options\. For more information, see [Specifying a Log Configuration in your Task Definition](#specify-log-config)\.
7. Complete the rest of the task definition wizard\.

### Specifying a Log Configuration in your Task Definition

Before your containers can send logs to CloudWatch, you must specify the `awslogs` log driver for containers in your task definition\. This section describes the log configuration for a container to use the `awslogs` log driver\. 

The task definition JSON shown below has a `logConfiguration` object specified for each container; one for the WordPress container that sends logs to a log group called `awslogs-wordpress`, and one for a MySQL container that sends logs to a log group called `awslogs-mysql`\. Both containers use the `awslogs-example` log stream prefix\.

```
{
    "containerDefinitions": [
        {
            "name": "wordpress",
            "links": [
                "mysql"
            ],
            "image": "wordpress",
            "essential": true,
            "portMappings": [
                {
                    "containerPort": 80,
                    "hostPort": 80
                }
            ],
            "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                    "awslogs-group": "awslogs-wordpress",
                    "awslogs-region": "us-west-2",
                    "awslogs-stream-prefix": "awslogs-example"
                }
            },
            "memory": 500,
            "cpu": 10
        },
        {
            "environment": [
                {
                    "name": "MYSQL_ROOT_PASSWORD",
                    "value": "password"
                }
            ],
            "name": "mysql",
            "image": "mysql",
            "cpu": 10,
            "memory": 500,
            "essential": true,
            "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                    "awslogs-group": "awslogs-mysql",
                    "awslogs-region": "us-west-2",
                    "awslogs-stream-prefix": "awslogs-example"
                }
            }
        }
    ],
    "family": "awslogs-example"
}
```

In the Amazon ECS console, the log configuration for the `wordpress` container is specified as shown in the image below\. 

![\[Console log configuration\]](http://docs.aws.amazon.com/AmazonECS/latest/developerguide/images/awslogs-console-config.png)

After you have registered a task definition with the `awslogs` log driver in a container definition log configuration, you can run a task or create a service with that task definition to start sending logs to CloudWatch Logs\. For more information, see [Running Tasks](ecs_run_task.md) and [Creating a service](create-service.md)\.


## 7. Creating a CloudTrail to log ECS API calls

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.|

**Why?**

You need to use AWS CloudTrail service in order to capture all the activity done on ECS servers and send all the logs from Fargate and EC2 Instance type to centralized logging location. These logs are used but the CG Security Engineering Teams to detect malicious activity and threat detection.
Amazon ECS is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon ECS. CloudTrail captures all API calls for Amazon ECS as events, including calls from the Amazon ECS console and from code calls to the Amazon ECS API operations.
CloudTrail is enabled on your AWS account when you create the account. When activity occurs in Amazon ECS, that activity is recorded in a CloudTrail event along with other AWS service events in Event history. 

**How?**

**To create a CloudTrail trail with the AWS Management Console**

1. Sign in to the AWS Management Console and open the CloudTrail console at [https://console\.aws\.amazon\.com/cloudtrail/](https://console.aws.amazon.com/cloudtrail/)\.

2. On the CloudTrail service home page, the Trails page, or the Trails section of the Dashboard page, choose Create trail.

3. On the Create Trail page, for Trail name, type a name for your trail. For more information, see CloudTrail trail naming requirements.

4. If this is an AWS Organizations organization trail, you can choose to enable the trail for all accounts in your organization. You only see this option if you are signed in to the console with an IAM user or role in the management account. To successfully create an organization trail, be sure that the user or role has sufficient permissions. For more   information, see Creating a trail for an organization.

5. For Storage location, choose Create new S3 bucket to create a bucket. When you create a bucket, CloudTrail creates and applies the required bucket policies.

6. For Log file SSE-KMS encryption, choose Enabled if you want to encrypt your log files with SSE-KMS instead of SSE-S3. The default is Enabled. For more information about this encryption type, see Protecting Data Using Server-Side Encryption with Amazon S3-Managed Encryption Keys (SSE-S3).

   If you enable SSE-KMS encryption, choose a New or Existing AWS KMS key. In AWS KMS Alias, specify an alias, in the format alias/MyAliasName. For more information, see Updating a trail to use your KMS key. CloudTrail also supports AWS KMS multi-Region keys. For more information about multi-Region keys, see Using multi-Region keys in the AWS Key Management Service Developer Guide.


## 8. Enable VPC Flow Logs for ECS Cluster VPC EC2 Launch Types Only

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.|

**Why?**

You need to use VPC Flow Logs in order send all the logs from Fargate and EC2 Instance type to centralized logging location. These logs are used but the CG Security Engineering Teams to detect malicious activity and threat detection.VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. Flow log data can be published to Amazon CloudWatch Logs or Amazon S3.

Flow logs can help you with a number of tasks, such as:

 + Diagnosing overly restrictive security group rules

 + Monitoring the traffic that is reaching your instance

 + Determining the direction of the traffic to and from the network interfaces

 Flow log data is collected outside of the path of your network traffic, and therefore does not affect network throughput or latency. You can create or delete flow logs without any risk of impact to network performance.

**How?**

### Creating a flow log

You can create flow logs for your VPCs, subnets, or network interfaces\. Flow logs can publish data to CloudWatch Logs or Amazon S3\.

For more information, see [Creating a flow log that publishes to CloudWatch Logs](flow-logs-cwl.md#flow-logs-cwl-create-flow-log) and [Creating a flow log that publishes to Amazon S3](flow-logs-s3.md#flow-logs-s3-create-flow-log)\.


## 9. Scan images for Vulnerabilities

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.|

**Why?**

All images deployed in the ECS Cluster must be scanned for identifying vulnerabilities. Similar to their virtual machine counterparts, container images can contain binaries and application libraries with vulnerabilities or develop vulnerabilities over time. The best way to safeguard against exploits is by regularly scanning your images with an image scanner. 

**How?**

All the Teams running ECS Clusters should have a Twistlock agent running in the cluster, so that images deployed in the cluster are scanned by Twistlock Scanner (Prisma Cloud). Please contact PDS team if you dont have twistlock agent running in the Cluster.


## 10. Remove special permissions from images

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

All the images which are getting deployed in the ECS Cluster should not have elevated, privilages and special permissions

**How?**

The access rights flags setuid and setgid allow running an executable with the permissions of the owner or group of the executable. Remove all binaries with these access rights from your image as these binaries can be used to escalate privileges. Consider removing all shells and utilities like nc and curl that can be used for malicious purposes. You can find the files with setuid and setgid access rights by using the following command.

```
 find / -perm /6000 -type f -exec ls -ld {} \;
```
To remove these special permissions from these files, add the following directive to your container image.

```
RUN find / -xdev -perm /6000 -type f -exec chmod a-s {} \; || true
```


## 11. Run containers as non-root users

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

You should run containers as a non-root user. By default, containers run as the root user unless the USER directive is included in your Dockerfile. The default Linux capabilities that are assigned by Docker restrict the actions that can be run as root, but only marginally. For example, a container running as root is still not allowed to access devices.

**How?**

The user name to use inside the container should not be root. Please make sure that none of the user under container definition is root user.

For example

```
  "container_definitions": [
                {"name": "test-task", "user": "random"}
              ],
```
How to fix the Task Defintion in case of root user found.

Create a task definition revision.

1.  Open the Amazon ECS console.

2.  From the navigation bar, choose the region that contains your task definition.

3.  In the navigation pane, choose Task Definitions.

4.  On the Task Definitions page, select the box to the left of the task definition to revise and choose Create new revision.

5.  On the Create new revision of Task Definition page, change the existing Container Definitions.

6.  Under Security, remove root from the User field.

7.  Verify the information and choose Update, then Create.

8.  If your task definition is used in a service, update your service with the updated task definition.

9.  Deactivate previous task definition.


## 12. Use a read-only root file system

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

You should use a read-only root file system. A container's root file system is writable by default. When you configure a container with a RO (read-only) root file system it forces you to explicitly define where data can be persisted. This reduces your attack surface because the container's file system can't be written to unless permissions are specifically granted.

Enabling this option forces containers at runtime to explicitly define their data writing strategy to persist or not persist their data. This also reduces security attack vectors since the container instance’s filesystem cannot be tampered with or written to unless it has explicit read-write permissions on its filesystem folder and directories.

**How?**

The following is parameter in the TaskDefintion that can be configured

readonlyRootFilesystem
  + Type: Boolean
  + Required: no

When this parameter is true, the container is given read-only access to its root file system. This parameter maps to ReadonlyRootfs in the Create a container section of the Docker Remote API and the --read-only option to docker run.

Note
This parameter is not supported for Windows containers.

```
  "readonlyRootFilesystem": true|false
```


## 13. ECS data in transit must enforce TLS with version 1.2 or higher

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

Encrypting network traffic prevents unauthorized users from intercepting and reading data when that data is transmitted across a network. All the data in transit must be encrypted and enforce a TLS version of 1.2 or more.

**How?**

With Amazon ECS, network encryption can be implemented in any of the following ways.

1. With a service mesh (TLS):

   With AWS App Mesh, you can configure TLS connections between the Envoy proxies that are deployed with mesh endpoints. Two examples are virtual nodes and virtual gateways. The TLS certificates can come from AWS Certificate Manager (ACM).

    + Enabling Transport Layer Security (TLS)

    + Enable traffic encryption between services in AWS App Mesh using ACM certificates or customer provided certs

    + TLS ACM walkthrough

    + TLS file walkthrough

    + Envoy

2. End-to-end encryption with TLS certificates:

   This involves deploying a TLS certificate with the task. This can either be a self-signed certificate or a certificate from a trusted certificate authority. You can obtain the certificate by referencing a secret for the certificate. Otherwise, you can choose to run an container that issues a Certificate Signing Request (CSR) to ACM and then mounts the resulting secret to a shared volume.
   
    + [Maintaining transport layer security all the way to your containers using the Network Load Balancer with Amazon ECS part 1] (https://aws.amazon.com/blogs/compute/maintaining-transport-layer-security-all-the-way-to-your-container-using-the-network-load-balancer-with-amazon-ecs/)

    + [Maintaining Transport Layer Security (TLS) all the way to your container part 2: Using AWS Certificate Manager Private Certificate Authority] (https://aws.amazon.com/blogs/compute/maintaining-transport-layer-security-all-the-way-to-your-container-part-2-using-aws-certificate-manager-private-certificate-authority/)



## 14. Make sure ECS Task network interface does not have public IP address

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Control Definition Needed|Control Definition Description Needed|

**Why?**

Avoid using a public subnet or public IP addresses for private, internal tasks. According CG Security Standards we are not allowed to have any public IP address from ECS Services. It allows malicious actors to get into the network. When creating a Amazon ECS Service, you have a option to enable to "Assign public IP address". We should not allow any ECS Cluster have a public IP address. 

If you are running a service that handles private, internal information, you should not put it into a public subnet or use a public IP address. For example, imagine that you have one task, which is an API gateway for authentication and access control. You have another background worker task that handles sensitive information.

**How?**

In the example below we are going to show where to check if the resource is enabling public IP address. If the resource is deployed using cloud formation template, the following property " NetworkConfiguration.AwsvpcConfiguration.AssignPublicIp" needs to "DISABLED" and re deployed.

```
  # The service. The service is a resource which allows you to run multiple
  # copies of a type of task, and gather up their logs and metrics, as well
  # as monitor the number of running tasks and replace any that have crashed
  Service:
    Type: AWS::ECS::Service
    DependsOn: LoadBalancerRule
    Properties:
      NetworkConfiguration:
        AwsvpcConfiguration:
          AssignPublicIp: DISABLED
          SecurityGroups:
            - Fn::ImportValue:
                !Join [':', [!Ref 'StackName', 'FargateContainerSecurityGroup']]       
      TaskDefinition: !Ref 'TaskDefinition'
     
```


## 15. Use always Fargate launch type in ECS Cluster with version 1.4 and above

Capital Group:
|Control Statement|Description|
|------|----------------------|
|Need to be updated|Need to be updated|

**Why?**

Avoid using EC2 Launch Type as it as inheritent security risks if deployed without any customization. The security risk, the role when assumed with EC2 Launch type will have access to the roles of Ec2 Instance. There CG Security team recommends to always run workloads for ECS Cluster in Fargate. We also seen lot of ehanced security feature in version 1.4, there it is recommended to have a minimum version of 1.4 for Fargate for tasks running on ECS.

**How?**

Containers that are running on your container instances are not prevented from accessing the credentials that are supplied to the container instance profile (through the Amazon EC2 instance metadata server). Based on security and best practices unless there is an explicit need for choosing EC2 Instance Type workloads teams needs to adapt Fargate type for launching ECS Cluster.

Currently we have seen lot of security features enabled in Fargate 1.4, Specifically the following
  
  + Beginning on May 28, 2020, any new Amazon ECS task launched on Fargate using platform version 1.4.0 will have its ephemeral storage encrypted with an AES-256 encryption algorithm using an AWS owned encryption key

  + When using Secrets Manager to store sensitive data, you can inject a specific JSON key or a specific version of a secret as an environment variable or in a log configuration. 

  + The network traffic behavior to and from tasks has been updated. Starting with platform version 1.4.0, all Fargate tasks receive a single elastic network interface (referred to as the task ENI) and all network traffic flows through that ENI within your VPC and will be visible to you through your VPC flow logs.

  + CloudWatch Container Insights will include network performance metrics for Fargate tasks

  + Added support for the SYS_PTRACE Linux parameter in container definitions. For more information, see Linux Parameters.

The above are the few of the features from the over list. The following link contains detailed feature list https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform_versions.html



## Operational Best Practices


## 1. Utilizing AWS CloudWatch Container Insights

### Setting Up Container Insights on Amazon ECS for Cluster\- and Service\-Level Metrics

You can enable Container Insights on new and existing Amazon ECS clusters\. Container Insights collects metrics at the cluster, task, and service levels\. For existing clusters, you use the AWS CLI\. For new clusters, use either the Amazon ECS console or the AWS CLI\.

If you're using Amazon ECS on an Amazon EC2 instance, and you want to collect network and storage metrics from Container Insights, launch that instance using an AMI that includes Amazon ECS agent version 1\.29\. For information about updating your agent version, see [Updating the Amazon ECS Container Agent](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-update.html)

You can use the AWS CLI to set account\-level permission to enable Container Insights for any new Amazon ECS clusters created in your account\. To do so, enter the following command\.

```
aws ecs put-account-setting --name "containerInsights" --value "enabled"
```

### Setting Up Container Insights on Existing Amazon ECS Clusters

To enable Container Insights on an existing Amazon ECS cluster, enter the following command\. You must be running version 1\.16\.200 or later of the AWS CLI for the following command to work\.

```
aws ecs update-cluster-settings --cluster myCICluster --settings name=containerInsights,value=enabled
```

### Setting Up Container Insights on New Amazon ECS Clusters

There are two ways to enable Container Insights on new Amazon ECS clusters\. You can configure Amazon ECS so that all new clusters are enabled for Container Insights by default\. Otherwise, you can enable a new cluster when you create it\.

### Using the AWS Management Console

You can enable Container Insights on all new clusters by default, or on an individual cluster as you create it\.

**To enable Container Insights on all new clusters by default**

1. Open the Amazon ECS console at [https://console\.aws\.amazon\.com/ecs/](https://console.aws.amazon.com/ecs/)\.

1. In the navigation pane, choose **Account Settings**\.

1. Select the check box at the bottom of the page to enable the Container Insights default\.

If you haven't used the preceding procedure to enable Container Insights on all new clusters by default, use the following steps to create a cluster with Container Insights enabled\.

**To create a cluster with Container Insights enabled**

1. Open the Amazon ECS console at [https://console\.aws\.amazon\.com/ecs/](https://console.aws.amazon.com/ecs/)\.

1. In the navigation pane, choose **Clusters**\.

1. Choose **Create cluster**\.

1. On the next page, do the following:

   1. Name your cluster\.

   1. If you don’t have a VPC already, select the check box to create one\. You can use the default values for the VPC\.

   1. Fill out all other needed information, including instance type\.

   1. Select **Enabled Container Insights**\.

   1. Choose **Create**\.

You can now create task definitions, run tasks, and launch services in the cluster\. For more information, see the following:
+ [Creating a Task Definition](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-task-definition.html)
+ [Running Tasks](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_run_task.html)
+ [Creating a Service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-service.html)

### Setting Up Container Insights on New Amazon ECS Clusters Using the AWS CLI

To enable Container Insights on all new clusters by default, enter the following command\.

```
aws ecs put-account-setting --name "containerInsights" --value "enabled"
```

If you didn't use the preceding command to enable Container Insights on all new clusters by default, enter the following command to create a new cluster with Container Insights enabled\. You must be running version 1\.16\.200 or later of the AWS CLI for the following command to work\.

```
aws ecs create-cluster --cluster-name myCICluster --settings "name=containerInsights,value=enabled"
```

## 2. ECS Resources are tagged according to CG standards

**Capital Group:** <br>

|Control Statement|Description|
|------|----------------------|
|N/A| No security control currently defined.|

**Why?**

**How?**

Tagging resources in the cloud is an easy way for teams to provide information related to who owns the resource, what the resource is used for, as well as other important information related to the deployment lifecycle of the resource. CG has mandated that all cloud resources are to be tagged with certain important for cross-team use. Although most of the mandatory tags will be added through automation, one should still check to make sure that all newly deployed recources have the appropriate tags attached. please see the documentation below for the latest tagging standards.

[CG Cloud Tagging Strategy](https://confluence.capgroup.com/display/HCEA/Resource+Tagging+standards)
<br><br>

## 3. Configure tasks with CPU and Memory limits

**Capital Group:** <br>

|Control Statement|Description|
|------|----------------------|
|N/A| No security control currently defined.|

**Why?**

It is not best practice if you dont set the limits on CPU and Memory consumption for Task Definition. These not only help containers scale get better performance, but also allows to choose what kind of confgiuration you are providing based on the workload you are running.

**How?**

Please follow the configuration details that are avialble for limiting CPU and Memory usuage. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html

Task size
When you register a task definition, you can specify the total cpu and memory used for the task. This is separate from the cpu and memory values at the container definition level. For tasks hosted on Amazon EC2 instances, these fields are optional. For tasks hosted on Fargate, these fields are required and there are specific values for both cpu and memory that are supported.

The following parameter is allowed in a task definition:

```
cpu
    Type: string

    Required: conditional
```

Note
This parameter is not supported for Windows containers.

The hard limit of CPU units to present for the task. It can be expressed as an integer using CPU units, for example 1024, or as a string using vCPUs, for example 1 vCPU or 1 vcpu, in a task definition. When the task definition is registered, a vCPU value is converted to an integer indicating the CPU units.

For tasks hosted on Amazon EC2 instances, this field is optional. If your cluster does not have any registered container instances with the requested CPU units available, the task will fail. Supported values are between 128 CPU units (0.125 vCPUs) and 10240 CPU units (10 vCPUs).

For tasks hosted on Fargate, this field is required and you must use one of the following values, which determines your range of supported values for the memory parameter:

|CPU value|Memory value (MiB)|
|------|----------------------|
|256 (.25 vCPU)| 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)|
|512 (.5 vCPU)| 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)|
|1024 (1 vCPU)| 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)|
|2048 (2 vCPU)| Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)|
|4096 (4 vCPU)| Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)|


```
memory
    Type: string

    Required: conditional

```

Note
This parameter is not supported for Windows containers.

The hard limit of memory (in MiB) to present to the task. It can be expressed as an integer using MiB, for example 1024, or as a string using GB, for example 1GB or 1 GB, in a task definition. When the task definition is registered, a GB value is converted to an integer indicating the MiB.

For tasks hosted on Amazon EC2 instances, this field is optional and any value can be used. If a task-level memory value is specified then the container-level memory value is optional. If your cluster does not have any registered container instances with the requested memory available, the task will fail. If you are trying to maximize your resource utilization by providing your tasks as much memory as possible for a particular instance type, see Container Instance Memory Management.

For tasks hosted on Fargate, this field is required and you must use one of the following values, which determines your range of supported values for the cpu parameter:

|Memory value (MiB)| CPU Value |
|------|----------------------|
| 512 (0.5 GB), 1024 (1 GB), 2048 (2 GB)| 256 (.25 vCPU)|
| 1024 (1 GB), 2048 (2 GB), 3072 (3 GB), 4096 (4 GB)|512 (.5 vCPU)|
| 2048 (2 GB), 3072 (3 GB), 4096 (4 GB), 5120 (5 GB), 6144 (6 GB), 7168 (7 GB), 8192 (8 GB)|1024 (1 vCPU)|
| Between 4096 (4 GB) and 16384 (16 GB) in increments of 1024 (1 GB)|2048 (2 vCPU)
| Between 8192 (8 GB) and 30720 (30 GB) in increments of 1024 (1 GB)|4096 (4 vCPU)| 

## Endnotes
**Resources**<br>
1. https://docs.aws.amazon.com/ecs/index.html
2. https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/security.html
3. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html
4. https://docs.aws.amazon.com/AmazonECR/latest/userguide/ECR_on_ECS.html
5. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/vpc-endpoints.html
6. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-secrets.html
7. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying-sensitive-data-parameters.html
8. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html#enable_awslogs
9. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/logging-using-cloudtrail.html
10. https://docs.aws.amazon.com/vpc/latest/userguide/working-with-flow-logs.html
11. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/deploy-container-insights-ECS-cluster.html
12. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch_event_stream.html
13. https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-local.html
<br><br>

## Capital Group Glossary
**Data** - Digital pieces of information stored or transmitted for use with an information system from which understandable information is derived. Items that could be considered to be data are: Source code, meta-data, build artifacts, information input and output.

**Information System** - An organized assembly of resources and procedures for the collection, processing, maintenance, use, sharing, dissemination, or disposition of information. All systems, platforms, compute instances including and not limited to physical and virtual client endpoints, physical and virtual servers, software containers, databases, Internet of Things (IoT) devices, network devices, applications (internal and external), Serverless computing instances (i.e. AWS Lambda), vendor provided appliances, and third-party platforms, connected to the Capital Group network or used by Capital Group users or customers.

**Log** - a record of the events occurring within information systems and networks. Logs are composed of log entries; each entry contains information related to a specific event that has occurred within a system or network.

**Information** - communication or representation of knowledge such as facts, data, or opinions in any medium or form, including textual, numerical, graphic, cartographic, narrative, or audiovisual.

**Cloud computing** - A model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.

**Vulnerability**  - Weakness in an information system, system security procedures, internal controls, or implementation that could be exploited or triggered by a threat source. Note: The term weakness is synonymous for deficiency. Weakness may result in security and/or privacy risks.
