<img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png" alt="AWS" width="250"/>

# Amazon Virtual Private Cloud (VPC) - Security Playbook <!-- omit in toc -->
## NIST Cybersecurity Framework Alignment <!-- omit in toc -->

**Generated By:**  
Freddie Wilson  
Tony DeMarco

*AWS Professional Services*

## Disclaimer
> The following applies to this document and all other documents, information, data, and responses (written or verbal) provided by Amazon Web Services, Inc. or any of its affiliates (collectively, "**AWS**") in connection with responding to this request and other related requests (collectively, this "**Response**"): This Response is expressly (a) informational only and provided solely for discussion purposes, (b) non-binding and not an offer to contract that can be accepted by any party, (c) provided "as is" with no representations or warranties whatsoever, and (d) based on AWS's current knowledge and may change at any time due to a variety of factors such as changes to your requirements or changes to AWS's service offerings. All obligations must be set forth in a separate, definitive written agreement between the parties. Neither party will have any liability for any failure or refusal to enter into a definitive agreement. All use of AWS's service offerings will be governed by the AWS Customer Agreement available at [http://aws.amazon.com/agreement/](http://aws.amazon.com/agreement/) (or other definitive written agreement between the parties governing the use of AWS's service offerings) (as applicable, the "**Agreement**"). If the parties have an applicable Nondisclosure Agreement ("**NDA**"), then the NDA will apply to all Confidential Information (as defined in the NDA) disclosed in connection with this Response. AWS's pricing is publicly available and subject to change in accordance with the Agreement. Pricing information (if any) provided in this Response is only an estimate and is expressly not a binding quote. Fees and charges will be based on actual usage of AWS services, which may vary from the estimates provided. Nothing in this Response will modify or supplement the terms of the Agreement or the NDA. No part of this Response may be disclosed without AWS's prior written consent. 

## Table of Contents <!-- omit in toc -->
- [Disclaimer](#disclaimer)
- [Overview](#overview)
- [Preventative Controls](#preventative-controls)
  - [1. Implement Access Controls to Enforce Least Privilege](#1-implement-access-controls-to-enforce-least-privilege)
  - [2. Enforce Data Protection Standards](#2-enforce-data-protection-standards)
  - [3. Change the Default Security Group for the VPC](#3-change-the-default-security-group-for-the-vpc)
  - [4. Control Access to VPC Endpoints](#4-control-access-to-vpc-endpoints)
- [Detective](#detective)
  - [1. Utilize VPC Flow logs with Amazon CloudWatch](#1-utilize-vpc-flow-logs-with-amazon-cloudwatch)
  - [2. Monitor NAT gateway metrics using Amazon CloudWatch](#2-monitor-nat-gateway-metrics-using-amazon-cloudwatch)
  - [3. Publish flow logs to Amazon S3](#3-publish-flow-logs-to-amazon-s3)
- [Respond/Recover](#respondrecover)
  - [1. Create and Manage notifications for your endpoint service](#1-create-and-manage-notifications-for-your-endpoint-service)
- [Endnotes](#endnotes)
- [Capital Group Control Statements](#capital-group-control-statements)
- [Glossary](#glossary)

## Overview
AWS provides a number of security features for Amazon Virtual Private Cloud (VPC) which help you comply with the NIST Cybersecurity Framework. The following playbook will outline what the AWS best practices are, how they align to NIST, and how to implement these best practices within your organization.

These NIST Controls and Subcategories are not applicable to this service: ID, PR.AC-2, PR.AT, PR.DS (Unless stated), PR.IP (Unless Stated), PR.MA, PR.PT-2, DE.AE-4, DE.AE-5, DE.CM-2, DE.CM-6, DE.DP, RS.RP, RS.CO, RS.MI, RS.IM, RC

These Capital Group Control Statement is not applicable to this service: [9](#capital-group-control-statements)

## Preventative Controls
### 1. Implement Access Controls to Enforce Least Privilege
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.AC-1|Identities and credentials are issued, managed, verified, revoked, and audited for authorized devices, users and processes|
|PR.AC-3|Remote access is managed|
|PR.AC-4|Access permissions and authorizations are managed, incorporating the principles of least privilege and separation of duties|
|PR.AC-6|Identities are proofed and bound to credentials and asserted in interactions|
|PR.AC-7|Users, devices, and other assets are authenticated (e.g., single-factor, multi-factor) commensurate with the risk of the transaction (e.g., individuals’ security and privacy risks and other organizational risks)|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|5|AWS IAM User accounts are only to be created for use by services or products that do not support IAM Roles. Services are not allowed to create local accounts for human use within the service. All human user authentication will take place within CG’s Identity Provider.|
|8|AWS IAM User secrets, including passwords and secret access keys, are to be rotated every 90 days. Accounts created locally within any service must also have their secrets rotated every 90 days.|
|10|Administrative access to AWS resources will have MFA enabled|

**Why?** When you create custom policies, grant only the permissions required to perform a task. Start with a minimum set of permissions and grant additional permissions as necessary. Doing so is more secure than starting with permissions that are too lenient and then trying to tighten them later.  
To the extent that it's practical, define the conditions under which your identity-based policies allow access to a resource. For example, you can write conditions to specify a range of allowable IP addresses that a request must come from. You can also write conditions to allow requests only within a specified date or time range, or to require the use of SSL or MFA.

**How?** Amazon VPC shares its API namespace with Amazon EC2. Policy actions in Amazon VPC use the following prefix before the action: `ec2:`. For example, to grant someone permission to create a VPC with the Amazon EC2 `CreateVpc` API operation, you include the `ec2:CreateVpc` action in their policy.

Using the optional `Condition` element within an IAM policy allows you to grant or deny permissions to a user, group, or role, but only under certain circumstances. This allows you to enforce least privilege, where an administrator may need the ability to perform certain actions, but only under certain situations, or when performing the action within specified bounds.

*Example 1:*  
The following policy grants users permission to launch instances into any subnet within a specific VPC. The policy does this by applying a condition key (`ec2:Vpc`) to the subnet resource.

The policy also grants users permission to launch instances using only AMIs that have the tag `"department=dev"`.
```json
{
   "Version": "2012-10-17",
   "Statement": [{
      "Effect": "Allow",
      "Action": "ec2:RunInstances",
      "Resource": "arn:aws:ec2:region:account:subnet/*",
        "Condition": {
         "StringEquals": {
            "ec2:Vpc": "arn:aws:ec2:region:account:vpc/vpc-11223344556677889"
            }
      }
   },
   {
      "Effect": "Allow",
      "Action": "ec2:RunInstances",
      "Resource": "arn:aws:ec2:region::image/ami-*",
      "Condition": {
         "StringEquals": {
            "ec2:ResourceTag/department": "dev"
            }
      }
   },
   {
      "Effect": "Allow",
      "Action": "ec2:RunInstances",
      "Resource": [ 
         "arn:aws:ec2:region:account:instance/*",
         "arn:aws:ec2:region:account:volume/*",
         "arn:aws:ec2:region:account:network-interface/*",
         "arn:aws:ec2:region:account:key-pair/*",
         "arn:aws:ec2:region:account:security-group/*"
         ]
      }
   ]
}
```

*Example 2:*  
The following policy allows users to view and create security groups. It also allows them to add and remove inbound and outbound rules to any security group that's associated with `vpc-11223344556677889`.
```json
{
   "Version": "2012-10-17",
   "Statement": [{
      "Effect": "Allow",
      "Action": [
         "ec2:DescribeSecurityGroups", "ec2:DescribeVpcs", "ec2:CreateSecurityGroup"
      ],
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "ec2:DeleteSecurityGroup", "ec2:AuthorizeSecurityGroupIngress", "ec2:AuthorizeSecurityGroupEgress",
        "ec2:RevokeSecurityGroupIngress", "ec2:RevokeSecurityGroupEgress"
      ],
      "Resource": "arn:aws:ec2:*:*:security-group/*",
      "Condition":{
         "ArnEquals": {
            "ec2:Vpc": "arn:aws:ec2:*:*:vpc/vpc-11223344556677889"
         }
      }
    }
   ]
}
```

For a reference to the available actions, resources, and conditions within the VPC service (and therefore, EC2 as well), see [Endnote 1](#endnote-1).

### 2. Enforce Data Protection Standards
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.DS-1|Data-at-rest is protected|
|PR.DS-2|Data-in-transit is protected|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|1|All Data-at-rest must be encrypted and use a CG BYOK encryption key.|
|2|All Data-in-transit must be encrypted using certificates using CG Certificate Authority.|
|3|Keys storied in a Key Management System (KMS) should be created by Capital Group's hardware security module (HSM) and are a minimum of AES-256.|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.|

**Why?** The VPC service itself does not store any data, so data-at-rest requirements do not directly impact this service. However, the storage of VPC Flow Logs needs to be encrypted. VPC Flow Logs contain information about traffic moving through a VPC. This information includes source and destination IPs, ports, and times, among other relevant info.

**How?** All communications with the VPC API are encrypted using industry-standard TLS. There is no action required within the VPC service to comply with the data-at-rest requirement.

VPC Flow Logs are stored in CloudWatch Logs prior to being ingested by Splunk. Setting up a customer master key (CMK) for encrypting the logs at rest is relatively straight-forward. This can be done either during the log group creation, or at any point after creation.  
The only caveat to setting up the key to work with the log group is to set up the key policy with appropriate permissions. The following is a clip from a policy that allows CloudWatch Logs to use the key as long as it is only with a specific log group:  
```json
...
{
            "Effect": "Allow",
            "Principal": {
                "Service": "logs.region.amazonaws.com"
            },
            "Action": [
                "kms:Encrypt*",
                "kms:Decrypt*",
                "kms:ReEncrypt*",
                "kms:GenerateDataKey*",
                "kms:Describe*"
            ],
            "Resource": "*",
            "Condition": {
                "ArnEquals": {
                    "kms:EncryptionContext:aws:logs:arn": "arn:aws:logs:region:account-id:log-group:log-group-name"
                }
            }
        }
...
```

#### To associate the CMK with a log group when you create it <!-- omit in toc -->

Use the `create-log-group` command as follows:
```
aws logs create-log-group --log-group-name my-log-group --kms-key-id "key-arn"
```
#### To associate the CMK with an existing log group <!-- omit in toc -->

Use the `associate-kms-key` command as follows:
```
aws logs associate-kms-key --log-group-name my-log-group --kms-key-id "key-arn"
```

### 3. Change the Default Security Group for the VPC
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.PT-4|Communications and control networks are protected|
|PR.AC-3|Remote access is managed|
|PR.AC-5|Network integrity is protected (e.g., network segregation, network segmentation)|

**Why?** Your VPC automatically comes with a default security group. If you don't specify a different security group when you launch the instance, AWS will associate the default security group with your instance.

*Note*
*If you launch an instance in the Amazon EC2 console, the launch instance wizard automatically defines a `"launch-wizard-xx"` security group, which you can associate with the instance instead of the default security group.*

The following table describes the default rules for a default security group.
#### Inbound <!-- omit in toc -->
|Source|Protocol|Port range|Description|
|------|--------|----------|-----------|
|The security group ID (sg-xxxxxxxx)|All|All|Allow inbound traffic from network interfaces (and their associated instances) that are assigned to the same security group.|

#### Outbound <!-- omit in toc -->
|Destination|Protocol|Port range|Description|
|-----------|--------|----------|-----------|
|0.0.0.0/0|All|All|Allow all outbound IPv4 traffic.|
|::/0|All|All|Allow all outbound IPv6 traffic. This rule is added by default if you create a VPC with an IPv6 CIDR block or if you associate an IPv6 CIDR block with your existing VPC.|

**How?** You can't delete this group; however, you can change the group's rules. The procedure is the same as modifying any other security group. Based on the use case for each specific VPC, the default Security Group should allow the minimum traffic required for basic functionality.

When you add or remove a rule, any instances already assigned to the security group are subject to the change.

If you have a VPC peering connection, you can reference security groups from the peer VPC as the source or destination in your security group rules. For more information, see [Endnote 2](#endnote-2).

#### To add a rule using the console <!-- omit in toc -->

1. Open the Amazon VPC console at <https://console.aws.amazon.com/vpc/>.
2. In the navigation pane, choose **Security Groups**.
3. Select the security group to update.
4. Choose **Actions, Edit inbound rules** or **Actions, Edit outbound rules**.
5. Choose **Add rule**. For **Type**, select the traffic type, and then specify the source (inbound rules) or destination (outbound rules).  
   The use of address range `0.0.0.0/0` is prohibited in production environments, and is only allowed temporarily in development. This will enable all IPv4 addresses to access your instance. To restrict access, enter a specific IP address or range of addresses.
6. Choose **Save rules**.

#### To delete a rule using the console <!-- omit in toc -->

1. Open the Amazon VPC console at <https://console.aws.amazon.com/vpc/>.
2. In the navigation pane, choose **Security Groups**.
3. Select the security group to update.
4. Choose **Actions, Edit inbound rules** or **Actions, Edit outbound rules**.
5. Choose the delete button (“x”) to the right of the rule that you want to delete.
6. Choose **Save rules**.

When you modify the protocol, port range, or source or destination of an existing security group rule using the console, the console deletes the existing rule and adds a new one for you.

#### To update a rule using the console <!-- omit in toc -->

1. Open the Amazon VPC console at <https://console.aws.amazon.com/vpc/>.
2. In the navigation pane, choose **Security Groups**.
3. Select the security group to update.
4. Choose **Actions, Edit inbound rules** or **Actions, Edit outbound rules**.
5. Modify the rule entry as required.
6. Choose **Save rules**.

If you are updating the protocol, port range, or source or destination of an existing rule using the Amazon EC2 API or a command line tool, you cannot modify the rule. Instead, you must delete the existing rule and add a new rule. To update the rule description only, you can use the `update-security-group-rule-descriptions-ingress` and `update-security-group-rule-descriptions-egress` commands.

#### To add a rule to a security group using the command line <!-- omit in toc -->

[`authorize-security-group-ingress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/authorize-security-group-ingress.html) and [`authorize-security-group-egress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/authorize-security-group-egress.html) (Select a command to see its CLI Reference)

#### To delete a rule from a security group using the command line <!-- omit in toc -->

[`revoke-security-group-ingress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/revoke-security-group-ingress.html) and [`revoke-security-group-egress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/revoke-security-group-egress.html) (Select a command to see its CLI Reference)

#### To update the description for a security group rule using the command line <!-- omit in toc -->

[`update-security-group-rule-descriptions-ingress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/update-security-group-rule-descriptions-ingress.html) and [`update-security-group-rule-descriptions-egress`](https://docs.aws.amazon.com/cli/latest/reference/ec2/update-security-group-rule-descriptions-egress.html) (Select a command to see its CLI Reference)

### 4. Control Access to VPC Endpoints
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|PR.PT-4|Communications and control networks are protected|
|PR.AC-3|Remote access is managed|
|PR.AC-5|Network integrity is protected (e.g., network segregation, network segmentation)|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|6|Any AWS service used by CG should not be directly available to the Internet and the default route is always the CG gateway.|
|7|Use of AWS IAM accounts are restricted to CG networks.|

**Why** As part of Capital Group's internal controls, all services must be accessed using the AWS network (or, backbone), meaning traffic cannot traverse the public Internet before reaching a service. This is accomplished in AWS using VPC Endpoints. These endpoints route all traffic from a VPC to a service using private IP addresses and DNS. As these are a required part of CG's cloud infrastructure, it is important that they are locked down to only those users who need to access them. This is done using IAM Policies.

**How** By default, IAM users do not have permission to work with endpoints. You can create an IAM user policy that grants users the permissions to create, modify, describe, and delete endpoints. The following is an example, which allows the attached principal to perform any actions pertaining to VPC Endpoints.
```json
{
    "Version": "2012-10-17",
    "Statement":[{
    "Effect":"Allow",
    "Action":"ec2:*VpcEndpoint*",
    "Resource":"*"
    }
  ]
}
```

It is possible to further restrict the actions available to the principal, and when they are available. This is similar to control number 1, mentioned earlier. As an example, you can use the `ec2:VpceServiceName` condition key to control what VPC endpoint can be created based on the VPC endpoint service name. In the following example, you can only create or VPC endpoint when the service name is `com.amazonaws.us-east-1.s3`. To use this example, substitute the account ID, the service name, and the Region (unless you are using the us-east-1 Region).
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "ec2:CreateVpcEndpoint",
            "Resource": [
                "arn:aws:ec2:us-east-1:accountId:vpc-endpoint/*"
            ],
            "Condition": {
                "StringEquals": {
                    "ec2:VpceServiceName": [
                        "com.amazonaws.us-east-1.s3"
                    ]
                }
            }
        }
    ]
}
```

## Detective
### 1. Utilize VPC Flow logs with Amazon CloudWatch
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|DE.AE-2|Detected events are analyzed to understand attack targets and methods|
|DE.AE-3|Event data are aggregated and correlated from multiple sources and sensors|
|DE.AE-4|Impact of an event is determined|
|DE.CM-1|The network is monitored to detect potential cybersecurity events|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch|


**Why?** 
Flow logs capture information about the IP traffic going to and from network interfaces in your VPC. You can create a flow log for a VPC, subnet, or individual network interface. Flow log data is published to CloudWatch Logs or Amazon S3, and can help you diagnose overly restrictive or overly permissive security group and network ACL rules.

**How?** 
#### Publish flow logs to CloudWatch Logs <!-- omit in toc -->

Flow logs can publish flow log data directly to Amazon CloudWatch\.

When publishing to CloudWatch Logs, flow log data is published to a log group, and each network interface has a unique log stream in the log group\. Log streams contain flow log records\. You can create multiple flow logs that publish data to the same log group\. If the same network interface is present in one or more flow logs in the same log group, it has one combined log stream\. If you've specified that one flow log should capture rejected traffic, and the other flow log should capture accepted traffic, then the combined log stream captures all traffic\.

In CloudWatch Logs, the **timestamp** field corresponds to the start time that's captured in the flow log record\. The **ingestionTime** field indicates the date and time when the flow log record was received by CloudWatch Logs\. This timestamp is later than the end time that's captured in the flow log record\.

#### IAM roles for publishing flow logs to CloudWatch Logs <!-- omit in toc -->

The IAM role that's associated with your flow log must have sufficient permissions to publish flow logs to the specified log group in CloudWatch Logs\. The IAM role must belong to your AWS account\.

The IAM policy that's attached to your IAM role must include at least the following permissions\.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
        "logs:DescribeLogGroups",
        "logs:DescribeLogStreams"
      ],
      "Effect": "Allow",
      "Resource": "*"
    }
  ]
}
```

Also ensure that your role has a trust relationship that allows the flow logs service to assume the role\.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "",
      "Effect": "Allow",
      "Principal": {
        "Service": "vpc-flow-logs.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
```

Users must also have permissions to use the iam:PassRole action for the IAM role that's associated with the flow log\.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["iam:PassRole"],
      "Resource": "arn:aws:iam::account-id:role/flow-log-role-name"
    }
  ]
}
```

You can update an existing role or use the following procedure to create a new role for use with flow logs\.

#### Creating a flow logs role <!-- omit in toc -->

**To create an IAM role for flow logs**

1. Open the IAM console at [https://console\.aws\.amazon\.com/iam/](https://console.aws.amazon.com/iam/)\.

1. In the navigation pane, choose **Roles**, **Create role**\.

1. Choose **EC2** as the service to use this role\. For **Use case**, choose **EC2**\. Choose **Next: Permissions**\.

1. On the **Attach permissions policies** page, choose **Next: Tags** and optionally add tags\. Choose **Next: Review**\.

1. Enter a name for your role \(for example, `Flow-Logs-Role`\) and optionally provide a description\. Choose **Create role**\.

1. Select the name of your role\. For **Permissions**, choose **Add inline policy**, **JSON**\.

1. Copy the first policy from [IAM roles for publishing flow logs to CloudWatch Logs](#flow-logs-iam) and paste it in the window\. Choose **Review policy**\.

1. Enter a name for your policy, and choose **Create policy**\.

1. Select the name of your role\. For **Trust relationships**, choose **Edit trust relationship**\. In the existing policy document, change the service from `ec2.amazonaws.com` to `vpc-flow-logs.amazonaws.com`\. Choose **Update Trust Policy**\.

1. On the **Summary** page, note the ARN for your role\. You need this ARN when you create your flow log\.

#### Creating a flow log that publishes to CloudWatch Logs <!-- omit in toc -->

You can create flow logs for your VPCs, subnets, or network interfaces\.

**To create a flow log for a network interface using the console**

1. Open the Amazon EC2 console at [https://console\.aws\.amazon\.com/ec2/](https://console.aws.amazon.com/ec2/)\.

1. In the navigation pane, choose **Network Interfaces**\.

1. Select one or more network interfaces and choose **Actions**, **Create flow log**\.

1. For **Filter**, specify the type of IP traffic data to log\. Choose **All** to log accepted and rejected traffic, **Rejected** to record only rejected traffic, or **Accepted** to record only accepted traffic\.

1. For **Maximum aggregation interval**, choose the maximum period of time during which a flow is captured and aggregated into one flow log record\.

1. For **Destination**, choose **Send to CloudWatch Logs**\.

1. For **Destination log group**, enter the name of a log group in CloudWatch Logs to which the flow logs are to be published\. If you specify the name of a log group that does not exist, we attempt to create the log group for you\.

1. For **IAM role**, specify the name of the role that has permissions to publish logs to CloudWatch Logs\.

1. For **Format**, specify the format for the flow log record\.
   + To use the default flow log record format, choose **AWS default format**\.
   + To create a custom format, choose **Custom format**\. For **Log format**, choose the fields to include in the flow log record\.
**Tip**  
To create a custom flow log that includes the default format fields, first choose **AWS default format**, copy the fields in **Format preview**, then choose **Custom format** and paste the fields in the text box\.

1. \(Optional\) Choose **Add Tag** to apply tags to the flow log\.

1. Choose **Create**\.

**To create a flow log for a VPC or a subnet using the console**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

1. In the navigation pane, choose **Your VPCs** or **Subnets**\.

1. Select one or more VPCs or subnets and then choose **Actions**, **Create flow log**\.

1. For **Filter**, specify the type of IP traffic data to log\. Choose **All** to log accepted and rejected traffic, **Rejected** to record only rejected traffic, or **Accepted** to record only accepted traffic\.

1. For **Maximum aggregation interval**, choose the maximum period of time during which a flow is captured and aggregated into one flow log record\.

1. For **Destination**, choose **Send to CloudWatch Logs**\.

1. For **Destination log group**, enter the name of a log group in CloudWatch Logs to which the flow logs are to be published\. If you specify the name of a log group that does not exist, we attempt to create the log group for you\.

1. For **IAM role**, specify the name of the IAM role that has permissions to publish logs to CloudWatch Logs\.

1. For **Format**, specify the format for the flow log record\.
   + To use the default flow log record format, choose **AWS default format**\.
   + To create a custom format, choose **Custom format**\. For **Log format**, choose the fields to include in the flow log record\.
**Tip**  
To create a custom flow log that includes the default format fields, first choose **AWS default format**, copy the fields in **Format preview**, then choose **Custom format** and paste the fields in the text box\.

1. \(Optional\) Choose **Add Tag** to apply tags to the flow log\.

1. Choose **Create**\.

**To create a flow log that publishes to CloudWatch Logs using a command line tool**  
Use one of the following commands\.
+ [create\-flow\-logs](https://docs.aws.amazon.com/cli/latest/reference/ec2/create-flow-logs.html) \(AWS CLI\)
+ [New\-EC2FlowLogs](https://docs.aws.amazon.com/powershell/latest/reference/items/New-EC2FlowLogs.html) \(AWS Tools for Windows PowerShell\)
+ [CreateFlowLogs](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateFlowLogs.html) \(Amazon EC2 Query API\)

The following AWS CLI example creates a flow log that captures all accepted traffic for subnet `subnet-1a2b3c4d`\. The flow logs are delivered to a log group in CloudWatch Logs called `my-flow-logs`, in account 123456789101, using the IAM role `publishFlowLogs`\.

```
aws ec2 create-flow-logs --resource-type Subnet --resource-ids subnet-1a2b3c4d --traffic-type ACCEPT --log-group-name my-flow-logs --deliver-logs-permission-arn arn:aws:iam::123456789101:role/publishFlowLogs
```

#### Processing flow log records in CloudWatch Logs <!-- omit in toc -->

You can work with flow log records as you would with any other log events collected by CloudWatch Logs\. For more information about monitoring log data and metric filters, see [Searching and Filtering Log Data](https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/MonitoringLogData.html) in the *Amazon CloudWatch User Guide*\.

#### Example: Creating a CloudWatch metric filter and alarm for a flow log <!-- omit in toc -->

In this example, you have a flow log for `eni-1a2b3c4d`\. You want to create an alarm that alerts you if there have been 10 or more rejected attempts to connect to your instance over TCP port 22 \(SSH\) within a 1\-hour time period\. First, you must create a metric filter that matches the pattern of the traffic for which to create the alarm\. Then, you can create an alarm for the metric filter\.

**To create a metric filter for rejected SSH traffic and create an alarm for the filter**

1. Open the CloudWatch console at [https://console\.aws\.amazon\.com/cloudwatch/](https://console.aws.amazon.com/cloudwatch/)\.

1. In the navigation pane, choose **Logs**\.

1. Choose the associated **Metric Filters** value for the log group for your flow log, and then choose **Add Metric Filter**\.

1. For **Filter Pattern**, enter the following\.

   ```
   [version, account, eni, source, destination, srcport, destport="22", protocol="6", packets, bytes, windowstart, windowend, action="REJECT", flowlogstatus]
   ```

1. For **Select Log Data to Test**, select the log stream for your network interface\. \(Optional\) To view the lines of log data that match the filter pattern, choose **Test Pattern**\. When you're ready, choose **Assign Metric**\.

1. Provide a metric namespace and name, and ensure that the metric value is set to **1**\. When you're done, choose **Create Filter**\.

1. In the navigation pane, choose **Alarms**, **Create Alarm**\.

1. In the **Custom Metrics** section, choose the namespace for the metric filter that you created\.

   It can take a few minutes for a new metric to display in the console\.

1. Select the metric name that you created, and choose **Next**\.

1. Enter a name and description for the alarm\. For the **is** fields, choose **>=** and enter **10**\. For the **for** field, leave the default **1** for the consecutive periods\.

1. For **Period**, choose **1 Hour**\. For **Statistic**, choose **Sum**\. The `Sum` statistic ensures that you are capturing the total number of data points for the specified time period\. 

1. In the **Actions** section, you can choose to send a notification to an existing list\. Or, you can create a new list and enter the email addresses that should receive a notification when the alarm is triggered\. When you are done, choose **Create Alarm**\.
   
### 2. Monitor NAT gateway metrics using Amazon CloudWatch
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|DE.CM-1|The network is monitored to detect potential cybersecurity events|
|DE.AE-2|Detected events are analyzed to understand attack targets and methods|
|DE.AE-3|Event data are aggregated and correlated from multiple sources and sensors|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch|

**Why?** 
Monitoring your NAT gateway using Amazon CloudWatch collects information from your NAT gateway and creates readable, near real\-time metrics\. You can use this information to monitor and troubleshoot your NAT gateway\. NAT gateway metric data is provided at 1\-minute intervals, and statistics are recorded for a period of 15 months\.
**How?** 

#### Monitoring NAT gateways using Amazon CloudWatch <!-- omit in toc -->


#### NAT gateway metrics and dimensions <!-- omit in toc -->

The following metrics are available for your NAT gateways\.


| Metric | Description | 
| --- | --- | 
|  `ActiveConnectionCount`  |  The total number of concurrent active TCP connections through the NAT gateway\. A value of zero indicates that there are no active connections through the NAT gateway\. Units: Count Statistics: The most useful statistic is `Max`\.  | 
|  `BytesInFromDestination`  |  The number of bytes received by the NAT gateway from the destination\. If the value for `BytesOutToSource` is less than the value for `BytesInFromDestination`, there may be data loss during NAT gateway processing, or traffic being actively blocked by the NAT gateway\. Units: Bytes Statistics: The most useful statistic is `Sum`\.  | 
|  `BytesInFromSource`  |  The number of bytes received by the NAT gateway from clients in your VPC\. If the value for `BytesOutToDestination` is less than the value for `BytesInFromSource`, there may be data loss during NAT gateway processing\. Units: Bytes Statistics: The most useful statistic is `Sum`\.  | 
|  `BytesOutToDestination`  |  The number of bytes sent out through the NAT gateway to the destination\. A value greater than zero indicates that there is traffic going to the internet from clients that are behind the NAT gateway\. If the value for `BytesOutToDestination` is less than the value for `BytesInFromSource`, there may be data loss during NAT gateway processing\. Unit: Bytes Statistics: The most useful statistic is `Sum`\.  | 
|  `BytesOutToSource`  |  The number of bytes sent through the NAT gateway to the clients in your VPC\. A value greater than zero indicates that there is traffic coming from the internet to clients that are behind the NAT gateway\. If the value for `BytesOutToSource` is less than the value for `BytesInFromDestination`, there may be data loss during NAT gateway processing, or traffic being actively blocked by the NAT gateway\. Units: Bytes Statistics: The most useful statistic is `Sum`\.  | 
|  `ConnectionAttemptCount`  |  The number of connection attempts made through the NAT gateway\. If the value for `ConnectionEstablishedCount` is less than the value for `ConnectionAttemptCount`, this indicates that clients behind the NAT gateway attempted to establish new connections for which there was no response\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `ConnectionEstablishedCount`  |  The number of connections established through the NAT gateway\. If the value for `ConnectionEstablishedCount` is less than the value for `ConnectionAttemptCount`, this indicates that clients behind the NAT gateway attempted to establish new connections for which there was no response\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `ErrorPortAllocation`  |  The number of times the NAT gateway could not allocate a source port\.  A value greater than zero indicates that too many concurrent connections are open through the NAT gateway\. Units: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `IdleTimeoutCount`  |  The number of connections that transitioned from the active state to the idle state\. An active connection transitions to idle if it was not closed gracefully and there was no activity for the last 350 seconds\. A value greater than zero indicates that there are connections that have been moved to an idle state\. If the value for `IdleTimeoutCount` increases, it may indicate that clients behind the NAT gateway are re\-using stale connections\.  Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `PacketsDropCount`  |  The number of packets dropped by the NAT gateway\. A value greater than zero may indicate an ongoing transient issue with the NAT gateway\. If this value is high, see the [AWS service health dashboard](http://status.aws.amazon.com/)\. Units: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `PacketsInFromDestination`  |  The number of packets received by the NAT gateway from the destination\. If the value for `PacketsOutToSource` is less than the value for `PacketsInFromDestination`, there may be data loss during NAT gateway processing, or traffic being actively blocked by the NAT gateway\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `PacketsInFromSource`  |  The number of packets received by the NAT gateway from clients in your VPC\. If the value for `PacketsOutToDestination` is less than the value for `PacketsInFromSource`, there may be data loss during NAT gateway processing\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `PacketsOutToDestination`  |  The number of packets sent out through the NAT gateway to the destination\. A value greater than zero indicates that there is traffic going to the internet from clients that are behind the NAT gateway\. If the value for `PacketsOutToDestination` is less than the value for `PacketsInFromSource`, there may be data loss during NAT gateway processing\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 
|  `PacketsOutToSource`  |  The number of packets sent through the NAT gateway to the clients in your VPC\. A value greater than zero indicates that there is traffic coming from the internet to clients that are behind the NAT gateway\. If the value for `PacketsOutToSource` is less than the value for `PacketsInFromDestination`, there may be data loss during NAT gateway processing, or traffic being actively blocked by the NAT gateway\. Unit: Count Statistics: The most useful statistic is `Sum`\.  | 

To filter the metric data, use the following dimension\.


| Dimension | Description | 
| --- | --- | 
| NatGatewayId | Filter the metric data by the NAT gateway ID\. | 

#### Viewing NAT gateway CloudWatch metrics <!-- omit in toc -->

NAT gateway metrics are sent to CloudWatch at 1\-minute intervals\. You can view the metrics for your NAT gateways as follows\.

**To view metrics using the CloudWatch console**

Metrics are grouped first by the service namespace, and then by the various dimension combinations within each namespace\.

1. Open the CloudWatch console at [https://console\.aws\.amazon\.com/cloudwatch/](https://console.aws.amazon.com/cloudwatch/)\.

1. In the navigation pane, choose **Metrics**\.

1. Under **All metrics**, choose the **NAT gateway** metric namespace\.

1. To view the metrics, select the metric dimension\.

**To view metrics using the AWS CLI**  
At a command prompt, use the following command to list the metrics that are available for the NAT gateway service\.

```
aws cloudwatch list-metrics --namespace "AWS/NATGateway"
```

#### Creating CloudWatch alarms to monitor a NAT gateway <!-- omit in toc -->

You can create a CloudWatch alarm that sends an Amazon SNS message when the alarm changes state\. An alarm watches a single metric over a time period that you specify\. It sends a notification to an Amazon SNS topic based on the value of the metric relative to a given threshold over a number of time periods\. 

For example, you can create an alarm that monitors the amount of traffic coming in or leaving the NAT gateway\. The following alarm monitors the amount of outbound traffic from clients in your VPC through the NAT gateway to the internet\. It sends a notification when the number of bytes reaches a threshold of 5,000,000 during a 15\-minute period\.

**To create an alarm for outbound traffic through the NAT gateway**

1. Open the CloudWatch console at [https://console\.aws\.amazon\.com/cloudwatch/](https://console.aws.amazon.com/cloudwatch/)\.

1. In the navigation pane, choose **Alarms**, **Create Alarm**\.

1. Choose **NAT gateway**\.

1. Select the NAT gateway and the **BytesOutToDestination** metric and choose **Next**\.

1. Configure the alarm as follows, and choose **Create Alarm** when you are done:
   + Under **Alarm Threshold**, enter a name and description for your alarm\. For **Whenever**, choose **>=** and enter `5000000`\. Enter **1** for the consecutive periods\.
   + Under **Actions**, select an existing notification list or choose **New list** to create a new one\. 
   + Under **Alarm Preview**, select a period of 15 minutes and specify a statistic of **Sum**\.

You can create an alarm that monitors the `ErrorPortAllocation` metric and sends a notification when the value is greater than zero \(0\) for three consecutive 5\-minute periods\.

**To create an alarm to monitor port allocation errors**

1. Open the CloudWatch console at [https://console\.aws\.amazon\.com/cloudwatch/](https://console.aws.amazon.com/cloudwatch/)\.

1. In the navigation pane, choose **Alarms**, **Create Alarm**\.

1. Choose **NAT Gateway**\.

1. Select the NAT gateway and the **ErrorPortAllocation** metric and choose **Next**\.

1. Configure the alarm as follows, and choose **Create Alarm** when you are done:
   + Under **Alarm Threshold**, enter a name and description for your alarm\. For **Whenever**, choose **>** and enter `0`\. Enter **3** for the consecutive periods\.
   + Under **Actions**, select an existing notification list or choose **New list** to create a new one\. 
   + Under **Alarm Preview**, select a period of 5 minutes and specify a statistic of **Maximum**\.

For more examples of creating alarms, see [Creating Amazon CloudWatch Alarms](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html) in the *Amazon CloudWatch User Guide*\.

### 3. Publish flow logs to Amazon S3
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|DE.CM-1|The network is monitored to detect potential cybersecurity events|
|DE.AE-2|Detected events are analyzed to understand attack targets and methods|
|DE.AE-3|Event data are aggregated and correlated from multiple sources and sensors|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch|

**Why?** 
VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC
**How?** 
#### Publishing flow logs to Amazon S3 <!-- omit in toc -->

Flow logs can publish flow log data to Amazon S3\.

When publishing to Amazon S3, flow log data is published to an existing Amazon S3 bucket that you specify\. Flow log records for all of the monitored network interfaces are published to a series of log file objects that are stored in the bucket\. If the flow log captures data for a VPC, the flow log publishes flow log records for all of the network interfaces in the selected VPC\. 

To create an Amazon S3 bucket for use with flow logs, see [Create a Bucket](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html) in the *Amazon Simple Storage Service Getting Started Guide*\.

For information about multiple account logging, see [Central Logging in Multi\-Account Environments](https://aws.amazon.com/blogs/architecture/central-logging-in-multi-account-environments/)\.


#### Flow log files <!-- omit in toc -->

Flow logs collect flow log records, consolidate them into log files, and then publish the log files to the Amazon S3 bucket at 5\-minute intervals\. Each log file contains flow log records for the IP traffic recorded in the previous five minutes\.

The maximum file size for a log file is 75 MB\. If the log file reaches the file size limit within the 5\-minute period, the flow log stops adding flow log records to it\. Then it publishes the flow log to the Amazon S3 bucket, and creates a new log file\.

Log files are saved to the specified Amazon S3 bucket using a folder structure that is determined by the flow log's ID, Region, and the date on which they are created\. The bucket folder structure uses the following format\.

```
bucket_ARN/optional_folder/AWSLogs/aws_account_id/vpcflowlogs/region/year/month/day/log_file_name.log.gz
```

Similarly, the log file's file name is determined by the flow log's ID, Region, and the date and time that it was created by the flow logs service\. File names use the following format\.

```
aws_account_id_vpcflowlogs_region_flow_log_id_timestamp_hash.log.gz
```

**Note**  
The timestamp uses the `YYYYMMDDTHHmmZ` format\.

For example, the following shows the folder structure and file name of a log file for a flow log created by AWS account `123456789012`, for a resource in the `us-east-1` Region, on `June 20, 2018` at `16:20 UTC`\. It includes flow log records for `16:15:00` to `16:19:59`\. 

```
arn:aws:s3:::my-flow-log-bucket/AWSLogs/123456789012/vpcflowlogs/us-east-1/2018/06/20/123456789012_vpcflowlogs_us-east-1_fl-1234abcd_20180620T1620Z_fe123456.log.gz
```

In Amazon S3, the **Last modified** field for the flow log file indicates the date and time at which the file was uploaded to the Amazon S3 bucket\. This is later than the timestamp in the file name, and differs by the amount of time taken to upload the file to the Amazon S3 bucket\.

#### IAM policy for IAM principals that publish flow logs to Amazon S3 <!-- omit in toc -->

An IAM principal in your account, such as an IAM user, must have sufficient permissions to publish flow logs to the Amazon S3 bucket\. This includes permissions to work with specific `logs:` actions to create and publish the flow logs\. The IAM policy must include the following permissions\.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogDelivery",
        "logs:DeleteLogDelivery"
        ],
      "Resource": "*"
    }
  ]
}
```

#### Amazon S3 bucket permissions for flow logs <!-- omit in toc -->

By default, Amazon S3 buckets and the objects they contain are private\. Only the bucket owner can access the bucket and the objects stored in it\. However, the bucket owner can grant access to other resources and users by writing an access policy\.

The following bucket policy gives the flow log permission to publish logs to it\. If the bucket already has a policy with the following permissions, the policy is kept as is\.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AWSLogDeliveryWrite",
            "Effect": "Allow",
            "Principal": {"Service": "delivery.logs.amazonaws.com"},
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::bucket_name/optional_folder/AWSLogs/account_id/*",
            "Condition": {"StringEquals": {"s3:x-amz-acl": "bucket-owner-full-control"}}
        },
        {
            "Sid": "AWSLogDeliveryAclCheck",
            "Effect": "Allow",
            "Principal": {"Service": "delivery.logs.amazonaws.com"},
            "Action": "s3:GetBucketAcl",
            "Resource": "arn:aws:s3:::bucket_name"
        }
    ]
}
```

If the user creating the flow log owns the bucket, has `PutBucketPolicy` permissions for the bucket, and the bucket does not have a policy with sufficient log delivery permissions, we automatically attach the preceding policy to the bucket\. This policy overwrites any existing policy attached to the bucket\.

If the user creating the flow log does not own the bucket, or does not have the `GetBucketPolicy` and `PutBucketPolicy` permissions for the bucket, the flow log creation fails\. In this case, the bucket owner must manually add the above policy to the bucket and specify the flow log creator's AWS account ID\. For more information, see [How Do I Add an S3 Bucket Policy?](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/add-bucket-policy.html) in the *Amazon Simple Storage Service Console User Guide*\. If the bucket receives flow logs from multiple accounts, add a `Resource` element entry to the `AWSLogDeliveryWrite` policy statement for each account\. For example, the following bucket policy allows AWS accounts `123123123123` and `456456456456` to publish flow logs to a folder named `flow-logs` in a bucket named `log-bucket`\.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AWSLogDeliveryWrite",
            "Effect": "Allow",
            "Principal": {"Service": "delivery.logs.amazonaws.com"},
            "Action": "s3:PutObject",
            "Resource": [
            	"arn:aws:s3:::log-bucket/flow-logs/AWSLogs/123123123123/*",
            	"arn:aws:s3:::log-bucket/flow-logs/AWSLogs/456456456456/*"
            	],
            "Condition": {"StringEquals": {"s3:x-amz-acl": "bucket-owner-full-control"}}
        },
        {
            "Sid": "AWSLogDeliveryAclCheck",
            "Effect": "Allow",
            "Principal": {"Service": "delivery.logs.amazonaws.com"},
            "Action": "s3:GetBucketAcl",
            "Resource": "arn:aws:s3:::log-bucket"
        }
    ]
}
```

**Note**  
We recommend that you grant the `AWSLogDeliveryAclCheck` and `AWSLogDeliveryWrite` permissions to the *log delivery* service principal instead of individual AWS account ARNs\.

#### Required CMK key policy for use with SSE\-KMS buckets <!-- omit in toc -->

If you enabled server\-side encryption for your Amazon S3 bucket using AWS KMS\-managed keys \(SSE\-KMS\) with a customer managed Customer Master Key \(CMK\), you must add the following to the key policy for your CMK so that flow logs can write log files to the bucket\.

**Note**  
Add these elements to the policy for your CMK, not the policy for your bucket\.

```
{
    "Sid": "Allow VPC Flow Logs to use the key",
    "Effect": "Allow",
    "Principal": {
        "Service": [
            "delivery.logs.amazonaws.com"
        ]
    },
   "Action": [
       "kms:Encrypt",
       "kms:Decrypt",
       "kms:ReEncrypt*",
       "kms:GenerateDataKey*",
       "kms:DescribeKey"
    ],
    "Resource": "*"
}
```

#### Amazon S3 log file permissions <!-- omit in toc -->

In addition to the required bucket policies, Amazon S3 uses access control lists \(ACLs\) to manage access to the log files created by a flow log\. By default, the bucket owner has `FULL_CONTROL` permissions on each log file\. The log delivery owner, if different from the bucket owner, has no permissions\. The log delivery account has `READ` and `WRITE` permissions\. For more information, see [Access Control List \(ACL\) Overview](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html) in the *Amazon Simple Storage Service Developer Guide*\.

#### Creating a flow log that publishes to Amazon S3 <!-- omit in toc -->

After you have created and configured your Amazon S3 bucket, you can create flow logs for your VPCs, subnets, or network interfaces\.

**To create a flow log for a network interface using the console**

1. Open the Amazon EC2 console at [https://console\.aws\.amazon\.com/ec2/](https://console.aws.amazon.com/ec2/)\.

1. In the navigation pane, choose **Network Interfaces**\.

1. Select one or more network interfaces and choose **Actions**, **Create flow log**\.

1. For **Filter**, specify the type of IP traffic data to log\. Choose **All** to log accepted and rejected traffic, **Rejected** to record only rejected traffic, or **Accepted** to record only accepted traffic\.

1. For **Maximum aggregation interval**, choose the maximum period of time during which a flow is captured and aggregated into one flow log record\.

1. For **Destination**, choose **Send to an Amazon S3 bucket**\.

1. For **S3 bucket ARN**, specify the Amazon Resource Name \(ARN\) of an existing Amazon S3 bucket\. You can include a subfolder in the bucket ARN\. The bucket cannot use `AWSLogs` as a subfolder name, as this is a reserved term\.

   For example, to specify a subfolder named `my-logs` in a bucket named `my-bucket`, use the following ARN:

   `arn:aws:s3:::my-bucket/my-logs/`

   If you own the bucket, we automatically create a resource policy and attach it to the bucket\. For more information, see [Amazon S3 bucket permissions for flow logs](#flow-logs-s3-permissions)\.

1. For **Format**, specify the format for the flow log record\.
   + To use the default flow log record format, choose **AWS default format**\.
   + To create a custom format, choose **Custom format**\. For **Log format**, choose the fields to include in the flow log record\.
**Tip**  
To create a custom flow log that includes the default format fields, first choose **AWS default format**, copy the fields in **Format preview**, then choose **Custom format** and paste the fields in the text box\.

1. \(Optional\) Choose **Add Tag** to apply tags to the flow log\.

1. Choose **Create**\.

**To create a flow log for a VPC or a subnet using the console**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

1. In the navigation pane, choose **Your VPCs** or **Subnets**\.

1. Select one or more VPCs or subnets and then choose **Actions**, **Create flow log**\.

1. For **Filter**, specify the type of IP traffic data to log\. Choose **All** to log accepted and rejected traffic, **Rejected** to record only rejected traffic, or **Accepted** to record only accepted traffic\.

1. For **Maximum aggregation interval**, choose the maximum period of time during which a flow is captured and aggregated into one flow log record\.

1. For **Destination**, choose **Send to an Amazon S3 bucket**\.

1. For **S3 bucket ARN**, specify the Amazon Resource Name \(ARN\) of an existing Amazon S3 bucket\. You can include a subfolder in the bucket ARN\. The bucket cannot use `AWSLogs` as a subfolder name, as this is a reserved term\.

   For example, to specify a subfolder named `my-logs` in a bucket named `my-bucket`, use the following ARN:

   `arn:aws:s3:::my-bucket/my-logs/`

   If you own the bucket, we automatically create a resource policy and attach it to the bucket\. For more information, see [Amazon S3 bucket permissions for flow logs](#flow-logs-s3-permissions)\.

1. For **Format**, specify the format for the flow log record\.
   + To use the default flow log record format, choose **AWS default format**\.
   + To create a custom format, choose **Custom format**\. For **Log format**, choose each of the fields to include in the flow log record\.

1. \(Optional\) Choose **Add Tag** to apply tags to the flow log\.

1. Choose **Create**\.

**To create a flow log that publishes to Amazon S3 using a command line tool**  
Use one of the following commands\.
+ [create\-flow\-logs](https://docs.aws.amazon.com/cli/latest/reference/ec2/create-flow-logs.html) \(AWS CLI\)
+ [New\-EC2FlowLogs](https://docs.aws.amazon.com/powershell/latest/reference/items/New-EC2FlowLogs.html) \(AWS Tools for Windows PowerShell\)
+ [CreateFlowLogs](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateFlowLogs.html) \(Amazon EC2 Query API\)

The following AWS CLI example creates a flow log that captures all traffic for VPC `vpc-00112233344556677` and delivers the flow logs to an Amazon S3 bucket called `flow-log-bucket`\. The `--log-format` parameter specifies a custom format for the flow log records\.

```
aws ec2 create-flow-logs --resource-type VPC --resource-ids vpc-00112233344556677 --traffic-type ALL --log-destination-type s3 --log-destination arn:aws:s3:::flow-log-bucket/my-custom-flow-logs/ --log-format '${version} ${vpc-id} ${subnet-id} ${instance-id} ${srcaddr} ${dstaddr} ${srcport} ${dstport} ${protocol} ${tcp-flags} ${type} ${pkt-srcaddr} ${pkt-dstaddr}'
```

#### Processing flow log records in Amazon S3 <!-- omit in toc -->

The log files are compressed\. If you open the log files using the Amazon S3 console, they are decompressed and the flow log records are displayed\. If you download the files, you must decompress them to view the flow log records\.

You can also query the flow log records in the log files using Amazon Athena\. Amazon Athena is an interactive query service that makes it easier to analyze data in Amazon S3 using standard SQL\. For more information, see [Querying Amazon VPC Flow Logs](https://docs.aws.amazon.com/athena/latest/ug/vpc-flow-logs.html) in the *Amazon Athena User Guide*\.

#### Flow log records <!-- omit in toc -->

A flow log record represents a network flow in your VPC\. By default, each record captures a network internet protocol \(IP\) traffic flow \(characterized by a 5\-tuple on a per network interface basis\) that occurs within an *aggregation interval*, also referred to as a *capture window*\. 

By default, the record includes values for the different components of the IP flow, including the source, destination, and protocol\. 

When you create a flow log, you can use the default format for the flow log record, or you can specify a custom format\.


#### Aggregation interval <!-- omit in toc -->

The aggregation interval is the period of time during which a particular flow is captured and aggregated into a flow log record\. By default, the maximum aggregation interval is 10 minutes\. When you create a flow log, you can optionally specify a maximum aggregation interval of 1 minute\. Flow logs with a maximum aggregation interval of 1 minute produce a higher volume of flow log records than flow logs with a maximum aggregation interval of 10 minutes\.

When a network interface is attached to a [Nitro\-based instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances), the aggregation interval is always 1 minute or less, regardless of the specified maximum aggregation interval\.

After data is captured within an aggregation interval, it takes additional time to process and publish the data to CloudWatch Logs or Amazon S3\. This additional time could be up to 5 minutes to publish to CloudWatch Logs, and up to 10 minutes to publish to Amazon S3\.

#### Default format <!-- omit in toc -->

By default, the log line format for a flow log record is a space\-separated string that has the following set of fields in the following order\.

```
<version> <account-id> <interface-id> <srcaddr> <dstaddr> <srcport> <dstport> <protocol> <packets> <bytes> <start> <end> <action> <log-status>
```

For more information about the fields, see [Available fields](#flow-logs-fields)\. The default format captures only a subset of all of the available fields for a flow log record\. To capture all available fields or a different subset of fields, specify a custom format\. You cannot customize or change the default format\.

#### Custom format <!-- omit in toc -->

You can optionally specify a custom format for the flow log record\. For a custom format, you specify which fields to return in the flow log record, and the order in which they should appear\. This enables you to create flow logs that are specific to your needs and to omit fields that are not relevant to you\. A custom format can also help to reduce the need for separate processes to extract specific information from published flow logs\. You can specify any number of the available flow log fields, but you must specify at least one\.

#### Available fields <!-- omit in toc -->

The following table describes all of the available fields for a flow log record\. The **Version** column indicates the VPC Flow Logs version in which the field was introduced\.


| Field | Description | Version | 
| --- | --- | --- | 
|  version  |  The VPC Flow Logs version\. If you use the default format, the version is `2`\. If you use a custom format, the version is the highest version among the specified fields\. For example, if you only specify fields from version 2, the version is `2`\. If you specify a mixture of fields from versions 2, 3, and 4, the version is `4`\.  | 2 | 
|  account\-id  |  The AWS account ID of the owner of the source network interface for which traffic is recorded\. If the network interface is created by an AWS service, for example when creating a VPC endpoint or Network Load Balancer, the record may display `unknown` for this field\.  | 2 | 
|  interface\-id  |  The ID of the network interface for which the traffic is recorded\.  | 2 | 
|  srcaddr  |  The source address for incoming traffic, or the IPv4 or IPv6 address of the network interface for outgoing traffic on the network interface\. The IPv4 address of the network interface is always its private IPv4 address\. See also pkt\-srcaddr\.  | 2 | 
|  dstaddr  |  The destination address for outgoing traffic, or the IPv4 or IPv6 address of the network interface for incoming traffic on the network interface\. The IPv4 address of the network interface is always its private IPv4 address\. See also pkt\-dstaddr\.  | 2 | 
|  srcport  |  The source port of the traffic\.  | 2 | 
|  dstport  |  The destination port of the traffic\.  | 2 | 
|  protocol  |  The IANA protocol number of the traffic\. For more information, see [ Assigned Internet Protocol Numbers](http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml)\.  | 2 | 
|  packets  |  The number of packets transferred during the flow\.  | 2 | 
|  bytes  |  The number of bytes transferred during the flow\.  | 2 | 
|  start  |  The time, in Unix seconds, when the first packet of the flow was received within the aggregation interval\. This might be up to 60 seconds after the packet was transmitted or received on the network interface\.  | 2 | 
|  end  |  The time, in Unix seconds, when the last packet of the flow was received within the aggregation interval\. This might be up to 60 seconds after the packet was transmitted or received on the network interface\.  | 2 | 
|  action  |  The action that is associated with the traffic: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html)  | 2 | 
|  log\-status  |  The logging status of the flow log: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html)  | 2 | 
|  vpc\-id  |  The ID of the VPC that contains the network interface for which the traffic is recorded\.  | 3 | 
|  subnet\-id  |  The ID of the subnet that contains the network interface for which the traffic is recorded\.  | 3 | 
|  instance\-id  |  The ID of the instance that's associated with network interface for which the traffic is recorded, if the instance is owned by you\. Returns a '\-' symbol for a [requester\-managed network interface](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/requester-managed-eni.html); for example, the network interface for a NAT gateway\.  | 3 | 
|  tcp\-flags  |  The bitmask value for the following TCP flags: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html) ACK is reported only when it's accompanied with SYN\.  TCP flags can be OR\-ed during the aggregation interval\. For short connections, the flags might be set on the same line in the flow log record, for example, `19` for SYN\-ACK and FIN, and `3` for SYN and FIN\. For an example, see [TCP flag sequence](flow-logs-records-examples.md#flow-log-example-tcp-flag)\.  | 3 | 
|  type  |  The type of traffic: `IPv4`, `IPv6`, or `EFA`\. For more information about the Elastic Fabric Adapter \(EFA\), see [Elastic Fabric Adapter](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html)\.  | 3 | 
|  pkt\-srcaddr  |  The packet\-level \(original\) source IP address of the traffic\. Use this field with the srcaddr field to distinguish between the IP address of an intermediate layer through which traffic flows, and the original source IP address of the traffic\. For example, when traffic flows through [a network interface for a NAT gateway](flow-logs-records-examples.md#flow-log-example-nat), or where the IP address of a pod in Amazon EKS is different from the IP address of the network interface of the instance node on which the pod is running \(for communication within a VPC\)\.  | 3 | 
|  pkt\-dstaddr  |  The packet\-level \(original\) destination IP address for the traffic\. Use this field with the dstaddr field to distinguish between the IP address of an intermediate layer through which traffic flows, and the final destination IP address of the traffic\. For example, when traffic flows through [a network interface for a NAT gateway](flow-logs-records-examples.md#flow-log-example-nat), or where the IP address of a pod in Amazon EKS is different from the IP address of the network interface of the instance node on which the pod is running \(for communication within a VPC\)\.  | 3 | 
|  region  |  The Region that contains the network interface for which traffic is recorded\.  |  4  | 
|  az\-id  |  The ID of the Availability Zone that contains the network interface for which traffic is recorded\. If the traffic is from a sublocation, the record displays a '\-' symbol for this field\.  |  4  | 
| sublocation\-type |  The type of sublocation that's returned in the `sublocation-id` field: [\[See the AWS documentation website for more details\]](http://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html) If the traffic is not from a sublocation, the record displays a '\-' symbol for this field\.  |  4  | 
|  sublocation\-id  |  The ID of the sublocation that contains the network interface for which traffic is recorded\. If the traffic is not from a sublocation, the record displays a '\-' symbol for this field\.  |  4  | 

**Note**  
If a field is not applicable for a specific record, the record displays a '\-' symbol for that entry\.

#### Flow log limitations <!-- omit in toc -->

To use flow logs, you need to be aware of the following limitations:
+ You cannot enable flow logs for network interfaces that are in the EC2\-Classic platform\. This includes EC2\-Classic instances that have been linked to a VPC through ClassicLink\. 
+ You can't enable flow logs for VPCs that are peered with your VPC unless the peer VPC is in your account\.
+ After you've created a flow log, you cannot change its configuration or the flow log record format\. For example, you can't associate a different IAM role with the flow log, or add or remove fields in the flow log record\. Instead, you can delete the flow log and create a new one with the required configuration\. 
+ If your network interface has multiple IPv4 addresses and traffic is sent to a secondary private IPv4 address, the flow log displays the primary private IPv4 address in the `dstaddr` field\. To capture the original destination IP address, create a flow log with the `pkt-dstaddr` field\.
+ If traffic is sent to a network interface and the destination is not any of the network interface's IP addresses, the flow log displays the primary private IPv4 address in the `dstaddr` field\. To capture the original destination IP address, create a flow log with the `pkt-dstaddr` field\.
+ If traffic is sent from a network interface and the source is not any of the network interface's IP addresses, the flow log displays the primary private IPv4 address in the `srcaddr` field\. To capture the original source IP address, create a flow log with the `pkt-srcaddr` field\.
+ If traffic is sent to or sent by a network interface, the `srcaddr` and `dstaddr` fields in the flow log always display the primary private IPv4 address, regardless of the packet source or destination\. To capture the packet source or destination, create a flow log with the `pkt-srcaddr` and `pkt-dstaddr` fields\.
+ If you create a flow log in a Region introduced after March 20, 2019 \(an [opt\-in Region](https://docs.aws.amazon.com/general/latest/gr/rande-manage.html)\), such as Asia Pacific \(Hong Kong\) or Middle East \(Bahrain\), the destination Amazon S3 bucket must be in the same Region and the same AWS account as the flow log\. 
+ If you create a flow log in a Region introduced before March 20, 2019, the destination Amazon S3 bucket must be in the same Region as the flow log, or in another Region introduced before March 20, 2019\. You cannot specify an Amazon S3 bucket that's in an opt\-in Region\.
+ When your network interface is attached to a [Nitro\-based instance](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#ec2-nitro-instances), the aggregation interval is always 1 minute or less, regardless of the specified maximum aggregation interval\.

Flow logs do not capture all IP traffic\. The following types of traffic are not logged:
+ Traffic generated by instances when they contact the Amazon DNS server\. If you use your own DNS server, then all traffic to that DNS server is logged\. 
+ Traffic generated by a Windows instance for Amazon Windows license activation\.
+ Traffic to and from `169.254.169.254` for instance metadata\.
+ Traffic to and from `169.254.169.123` for the Amazon Time Sync Service\.
+ DHCP traffic\.
+ Traffic to the reserved IP address for the default VPC router\. For more information, see [VPC and subnet sizing](VPC_Subnets.md#VPC_Sizing)\.
+ Traffic between an endpoint network interface and a Network Load Balancer network interface\.
+ 
## Respond/Recover
### 1. Create and Manage notifications for your endpoint service
NIST CSF:
|NIST Subcategory Control|Description|
|-----------|------------------------|
|DE.AE-2|Detected events are analyzed to understand attack targets and methods|
|DE.AE-3|Event data are aggregated and correlated from multiple sources and sensors|
|DE.AE-4|Impact of events is determined|
|DE.AE-5|Incident alert thresholds are established|
|DE.CM-1|The network is monitored to detect potential cybersecurity events|

Capital Group:
|Control Statement|Description|
|------|----------------------|
|4|AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch|

**Why?** 
You can create a notification to receive alerts for specific events that occur on the endpoints that are attached to your endpoint service\.
**How?** 
#### Create and manage a notifications for an endpoint service <!-- omit in toc -->

You can receive an email when an endpoint request is accepted or rejected for your endpoint service\. To create a notification, you must associate an Amazon SNS topic with the notification\. You can subscribe to the SNS topic to receive an email notification when an endpoint event occurs\. For more information, see the [Amazon Simple Notification Service Developer Guide](https://docs.aws.amazon.com/sns/latest/dg/)\.

The Amazon SNS topic that you use for notifications must have a topic policy that allows the Amazon VPC endpoint service to publish notifications on your behalf\. Ensure that you include the following statement in your topic policy\. For more information, see [Managing Access to Your Amazon SNS Topics](https://docs.aws.amazon.com/sns/latest/dg/AccessPolicyLanguage.html) in the *Amazon Simple Notification Service Developer Guide*\.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "vpce.amazonaws.com"
      },
      "Action": "SNS:Publish",
      "Resource": "arn:aws:sns:region:account:topic-name"
    }
  ]
}
```

------
#### [ Console ] <!-- omit in toc -->

**To create a notification for an endpoint service**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

1. In the navigation pane, choose **Endpoint Services** and select your endpoint service\.

1. Choose **Notifications**, **Create Notification**\.

1. Choose the ARN for the SNS topic to associate with the notification\.

1. For **Events**, select the endpoint events for which to receive notifications\.

1. Choose **Create Notification**\.

After you create a notification, you can change the SNS topic that's associated with the notification\. You can also specify different endpoint events for the notification\.

**To modify a notification for an endpoint service**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

1. In the navigation pane, choose **Endpoint Services** and select your endpoint service\.

1. Choose **Notifications**, **Actions**, **Modify Notification**\.

1. Specify the ARN for the SNS topic and select or deselect the endpoint events as required\.

1. Choose **Modify Notification**\.

If you no longer need a notification, you can delete it\.

**To delete a notification**

1. Open the Amazon VPC console at [https://console\.aws\.amazon\.com/vpc/](https://console.aws.amazon.com/vpc/)\.

1. In the navigation pane, choose **Endpoint Services** and select your endpoint service\.

1. Choose **Notifications**, **Actions**, **Delete Notification**\.

1. Choose **Yes, Delete**\.

------
#### [ AWS CLI ] <!-- omit in toc -->

**To create and manage a notification using the AWS CLI**

1. To create a notification for an endpoint service, use the [create\-vpc\-endpoint\-connection\-notification](https://docs.aws.amazon.com/cli/latest/reference/ec2/create-vpc-endpoint-connection-notification.html) command and specify the ARN of the SNS topic, the events for which to be notified, and the ID of the endpoint service\.

   ```
   aws ec2 create-vpc-endpoint-connection-notification --connection-notification-arn arn:aws:sns:us-east-2:123456789012:VpceNotification --connection-events Connect Accept Delete Reject --service-id vpce-svc-1237881c0d25a3abc
   ```

   ```
   {
       "ConnectionNotification": {
           "ConnectionNotificationState": "Enabled", 
           "ConnectionNotificationType": "Topic", 
           "ServiceId": "vpce-svc-1237881c0d25a3abc", 
           "ConnectionEvents": [
               "Reject",
               "Accept",
               "Delete",
               "Connect"
           ], 
           "ConnectionNotificationId": "vpce-nfn-008776de7e03f5abc", 
           "ConnectionNotificationArn": "arn:aws:sns:us-east-2:123456789012:VpceNotification"
       }
   }
   ```

1. To view your notifications, use the [describe\-vpc\-endpoint\-connection\-notifications](https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-vpc-endpoint-connection-notifications.html) command\.

   ```
   aws ec2 describe-vpc-endpoint-connection-notifications
   ```

1. To change the SNS topic or endpoint events for the notification, use the [modify\-vpc\-endpoint\-connection\-notification](https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-vpc-endpoint-connection-notification.html) command\.

   ```
   aws ec2 modify-vpc-endpoint-connection-notification --connection-notification-id vpce-nfn-008776de7e03f5abc --connection-events Accept Reject --connection-notification-arn arn:aws:sns:us-east-2:123456789012:mytopic
   ```

1. To delete a notification, use the [delete\-vpc\-endpoint\-connection\-notifications](https://docs.aws.amazon.com/cli/latest/reference/ec2/delete-vpc-endpoint-connection-notifications.html) command\.

   ```
   aws ec2 delete-vpc-endpoint-connection-notifications --connection-notification-ids vpce-nfn-008776de7e03f5abc
   ```

------
#### [  AWS Tools for Windows PowerShell ] <!-- omit in toc -->

Use [New\-EC2VpcEndpointConnectionNotification](https://docs.aws.amazon.com/powershell/latest/reference/items/New-EC2VpcEndpointConnectionNotification.html), [Get\-EC2EndpointConnectionNotification](https://docs.aws.amazon.com/powershell/latest/reference/items/Get-EC2EndpointConnectionNotification.html), [Edit\-EC2VpcEndpointConnectionNotification](https://docs.aws.amazon.com/powershell/latest/reference/items/Edit-EC2VpcEndpointConnectionNotification.html), and [Remove\-EC2EndpointConnectionNotification](https://docs.aws.amazon.com/powershell/latest/reference/items/Remove-EC2EndpointConnectionNotification.html)\.

------
#### [ API ] <!-- omit in toc -->

Use [CreateVpcEndpointConnectionNotification](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-CreateVpcEndpointConnectionNotification.html), [DescribeVpcEndpointConnectionNotifications](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DescribeVpcEndpointConnectionNotifications.html), [ModifyVpcEndpointConnectionNotification](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-ModifyVpcEndpointConnectionNotification.html), and [DeleteVpcEndpointConnectionNotifications](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-DeleteVpcEndpointConnectionNotifications.html)\.

------

## Endnotes
### Endnote 1 <!-- omit in toc -->
[https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonec2.html](https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonec2.html)

### Endnote 2 <!-- omit in toc -->
[https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html](https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html)

## Capital Group Control Statements 
1. All Data-at-rest must be encrypted and use a CG BYOK encryption key.
2. All Data-in-transit must be encrypted using certificates using CG Certificate Authority.
3. Keys storied in a Key Management System (KMS) should be created by Capital Group's hardware security module (HSM) and are a minimum of AES-256.
4. AWS services should have logging enabled and those logs delivered to CloudTrail or Cloud Watch.
5. AWS IAM User accounts are only to be created for use by services or products that do not support IAM Roles. Services are not allowed to create local accounts for human use within the service. All human user authentication will take place within CG’s Identity Provider.
6. Any AWS service used by CG should not be directly available to the Internet and the default route is always the CG gateway.
7. Use of AWS IAM accounts are restricted to CG networks.
8. AWS IAM User secrets, including passwords and secret access keys, are to be rotated every 90 days. Accounts created locally within any service must also have their secrets rotated every 90 days.
9. Encryption keys are rotated annually.
10. Administrative access to AWS resources will have MFA enabled

## Glossary
**Data** - Digital pieces of information stored or transmitted for use with an information system from which understandable information is derived. Items considered to be data are: Source code, meta-data, build artifacts, information input and output.  
 
**Information System** - An organized assembly of resources and procedures for the collection, processing, maintenance, use, sharing, dissemination, or disposition of information. All systems, platforms, compute instances including and not limited to physical and virtual client endpoints, physical and virtual servers, software containers, databases, Internet of Things (IoT) devices, network devices, applications (internal and external), Serverless computing instances (i.e. AWS Lambda), vendor provided appliances, and third-party platforms, connected to the Capital Group network or used by Capital Group users or customers.
 
**Log** - a record of the events occurring within information systems and networks. Logs are composed of log entries; each entry contains information related to a specific event that has occurred within a system or network.
 
**Information** - communication or representation of knowledge such as facts, data, or opinions in any medium or form, including textual, numerical, graphic, cartographic, narrative, or audiovisual. 
 
**Cloud Computing** - A model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction.
 
**Vulnerability**  - Weakness in an information system, system security procedures, internal controls, or implementation that could be exploited or triggered by a threat source. Note: The term weakness is synonymous for deficiency. Weakness may result in security and/or privacy risks.